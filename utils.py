# utils.py (VERS√ÉO FINAL CORRIGIDA E OTIMIZADA)

import streamlit as st
import json, os, pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from fpdf import FPDF
import pandas as pd
import uuid
import base64
import google.generativeai as genai
from security import find_user, decrypt_token
from datetime import datetime, date, timedelta
import openai
from sklearn.linear_model import LinearRegression
import numpy as np
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText
from email.mime.application import MIMEApplication
from pathlib import Path
import re
from security import *
import fitz
import sendgrid
import io
import base64
import requests
from config import COLOR_THEMES
from sklearn.linear_model import LinearRegression
from datetime import datetime, date, timedelta
import html
from io import BytesIO
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle
from reportlab.lib.styles import getSampleStyleSheet
from reportlab.lib import colors
from reportlab.lib.units import inch
import unicodedata


def apply_filters(df, filters):
    """Aplica a lista de filtros do construtor de gr√°ficos a um DataFrame."""
    if not filters:
        return df
        
    df_filtered = df.copy()
    
    for f in filters:
        field = f.get('field')
        op = f.get('operator')
        value = f.get('value')

        if not field or not op or value is None or (isinstance(value, list) and not value):
            continue

        if field not in df_filtered.columns:
            st.warning(f"N√£o foi poss√≠vel aplicar o filtro: o campo '{field}' n√£o foi encontrado nos dados atuais.")
            continue

        try:
            if pd.api.types.is_datetime64_any_dtype(df_filtered[field]):
                 df_filtered[field] = pd.to_datetime(df_filtered[field], errors='coerce').dt.normalize()

            if op == '√© igual a':
                df_filtered = df_filtered[df_filtered[field] == value]
            elif op == 'n√£o √© igual a':
                df_filtered = df_filtered[df_filtered[field] != value]
            elif op == 'est√° em':
                df_filtered = df_filtered[df_filtered[field].isin(value)]
            elif op == 'n√£o est√° em':
                df_filtered = df_filtered[~df_filtered[field].isin(value)]
            
            elif op == 'maior que':
                df_filtered = df_filtered[pd.to_numeric(df_filtered[field], errors='coerce') > value]
            elif op == 'menor que':
                df_filtered = df_filtered[pd.to_numeric(df_filtered[field], errors='coerce') < value]
            elif op == 'entre' and len(value) == 2:
                df_filtered = df_filtered[pd.to_numeric(df_filtered[field], errors='coerce').between(value[0], value[1])]
            
            elif op == 'Per√≠odo Personalizado' and isinstance(value, (list, tuple)) and len(value) == 2:
                start_date = pd.to_datetime(value[0]).normalize()
                end_date = pd.to_datetime(value[1]).normalize()
                df_filtered = df_filtered[df_filtered[field].between(start_date, end_date)]
            
            elif op == 'Per√≠odos Relativos':
                days_map = {
                    "√öltimos 7 dias": 7, "√öltimos 14 dias": 14, "√öltimos 30 dias": 30,
                    "√öltimos 60 dias": 60, "√öltimos 90 dias": 90, "√öltimos 120 dias": 120,
                    "√öltimos 150 dias": 150, "√öltimos 180 dias": 180
                }
                days = days_map.get(value)
                if days:
                    end_date = pd.to_datetime(datetime.now().date())
                    start_date = end_date - timedelta(days=days)
                    df_filtered = df_filtered[df_filtered[field].between(start_date, end_date)]
        
        except Exception as e:
            st.warning(f"Ocorreu um erro inesperado ao aplicar o filtro no campo '{field}': {e}")
            continue
            
    return df_filtered

def load_config(file_path, default_value):
    if os.path.exists(file_path):
        with open(file_path, 'r', encoding='utf-8') as f:
            try: return json.load(f)
            except (json.JSONDecodeError, UnicodeDecodeError): return default_value
    return default_value

def save_config(data, file_path):
    with open(file_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, indent=4)

def convert_dates_in_filters(filters):
    processed_filters = []
    for f in filters:
        new_filter = f.copy()
        value = new_filter.get('value')
        
        if isinstance(value, (date, datetime)):
            new_filter['value'] = value.isoformat()
        elif isinstance(value, (list, tuple)):
            new_filter['value'] = [
                v.isoformat() if isinstance(v, (date, datetime)) else v 
                for v in value
            ]
            
        processed_filters.append(new_filter)
    return processed_filters

def parse_dates_in_filters(filters):
    processed_filters = []
    for f in filters:
        new_filter = f.copy()
        op = new_filter.get('operator')
        value = new_filter.get('value')
        
        if op == 'Per√≠odo Personalizado' and value and isinstance(value, (list, tuple)) and len(value) == 2:
            try:
                start_date_val, end_date_val = value
                
                def _to_date_obj(val):
                    if isinstance(val, str):
                        return datetime.strptime(val, '%Y-%m-%d').date()
                    if isinstance(val, datetime):
                        return val.date()
                    if isinstance(val, date):
                        return val
                    return None

                start_date = _to_date_obj(start_date_val)
                end_date = _to_date_obj(end_date_val)
                
                if start_date and end_date:
                    new_filter['value'] = (start_date, end_date)

            except (ValueError, TypeError):
                pass 
        
        processed_filters.append(new_filter)
    return processed_filters

@st.cache_data
def calculate_trendline(df, x_col, y_col):
    df_cleaned = df.dropna(subset=[x_col, y_col])
    if not pd.api.types.is_numeric_dtype(df_cleaned[x_col]) or \
       not pd.api.types.is_numeric_dtype(df_cleaned[y_col]) or \
       df_cleaned.empty:
        return None, None
    
    X = df_cleaned[[x_col]].values
    y = df_cleaned[y_col].values
    model = LinearRegression()
    model.fit(X, y)
    trend_y = model.predict(X)
    return df_cleaned[x_col], trend_y

def apply_chart_theme(fig, theme_name="Padr√£o Gauge"):
    """Aplica um tema de cores a uma figura Plotly, extraindo a sequ√™ncia de cores correta."""
    default_theme_key = list(COLOR_THEMES.keys())[0]
    theme_dict = COLOR_THEMES.get(theme_name, COLOR_THEMES[default_theme_key])
    
    if not isinstance(theme_dict, dict):
        theme_dict = COLOR_THEMES[default_theme_key]

    color_sequence = theme_dict.get('color_sequence', [])
    
    fig.update_layout(
        colorway=color_sequence,
        plot_bgcolor='rgba(0,0,0,0)',
        paper_bgcolor='rgba(0,0,0,0)',
        font=dict(family="Roboto, sans-serif", color="#3D3D3D"),
        xaxis=dict(gridcolor='rgba(220, 220, 220, 0.5)'),
        yaxis=dict(gridcolor='rgba(220, 220, 220, 0.5)'),
        legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1)
    )
    return fig

def render_chart(chart_config, df, chart_key):
    """Renderiza um gr√°fico com base na configura√ß√£o, com valida√ß√£o robusta e aplica√ß√£o de tema de cores."""
    try:
        if not isinstance(chart_config, dict):
            st.error(f"Erro: A configura√ß√£o deste gr√°fico √© inv√°lida e n√£o pode ser renderizada.")
            with st.expander("Ver dados corrompidos"):
                st.json(chart_config)
            return

        chart_key = f"chart_{chart_config.get('id', uuid.uuid4())}"
        chart_type = chart_config.get('type')
        default_theme = list(COLOR_THEMES.keys())[0]
        color_theme = chart_config.get('color_theme', default_theme)
        df_chart_filtered = apply_filters(df, chart_config.get('filters', []))

        # --- IN√çCIO DO BLOCO CORRIGIDO ---
        if chart_type in ['barra', 'barra_horizontal', 'linha_agregada', 'pizza', 'treemap', 'funil', 'tabela']:
            dimension = chart_config.get('dimension')
            measure = chart_config.get('measure')
            agg = chart_config.get('agg')
            if not dimension or not measure or not agg:
                st.warning("Configura√ß√£o de gr√°fico agregado inv√°lida.")
                return
            
            group_by_cols = [dimension]
            secondary_dimension = chart_config.get('secondary_dimension')
            if secondary_dimension: 
                group_by_cols.append(secondary_dimension)
            
            if measure == "Contagem de Issues":
                agg_df = df_chart_filtered.groupby(group_by_cols).size().reset_index(name='Contagem')
                agg_col = 'Contagem'
            else:
                agg_func_map = {'Soma': 'sum', 'M√©dia': 'mean', 'Contagem': 'count', 'Contagem Distinta': 'nunique'}
                agg_name_map = {'Soma': 'Soma de', 'M√©dia': 'M√©dia de', 'Contagem': 'Contagem de', 'Contagem Distinta': 'Contagem Distinta de'}
                agg_df = df_chart_filtered.groupby(group_by_cols)[measure].agg(agg_func_map[agg]).reset_index()
                agg_col = f"{agg_name_map[agg]} {measure}"
                agg_df.rename(columns={measure: agg_col}, inplace=True)

            y_axis_title_text = agg_col
            if chart_config.get('y_axis_format') == 'hours' and agg_col in agg_df.columns:
                agg_df[agg_col] = agg_df[agg_col] / 3600.0
                y_axis_title_text = f"{agg_col} (horas)"
            
            sort_by = chart_config.get('sort_by')
            if sort_by:
                if "Dimens√£o" in sort_by:
                    ascending = "A-Z" in sort_by
                    agg_df = agg_df.sort_values(by=dimension, ascending=ascending)
                elif "Medida" in sort_by:
                    ascending = "Crescente" in sort_by
                    agg_df = agg_df.sort_values(by=agg_col, ascending=ascending)
            
            top_n = chart_config.get('top_n')
            if top_n and isinstance(top_n, int) and top_n > 0: 
                agg_df = agg_df.head(top_n)
            
            if chart_config.get('show_as_percentage'):
                total = agg_df[agg_col].sum()
                if total > 0: agg_df[agg_col] = (agg_df[agg_col] / total) * 100
            
            fig = None
            theme_colors = COLOR_THEMES.get(color_theme, COLOR_THEMES[default_theme])
            if not isinstance(theme_colors, dict):
                theme_colors = COLOR_THEMES[default_theme]

            if chart_type == 'barra': fig = px.bar(agg_df, x=dimension, y=agg_col, color=secondary_dimension)
            elif chart_type == 'barra_horizontal': fig = px.bar(agg_df, y=dimension, x=agg_col, orientation='h', color=secondary_dimension)
            elif chart_type == 'linha_agregada': fig = px.line(agg_df, x=dimension, y=agg_col, markers=True, color=secondary_dimension)
            elif chart_type == 'pizza': fig = px.pie(agg_df, names=dimension, values=agg_col)
            elif chart_type == 'treemap':
                path = [dimension]
                if secondary_dimension: path.append(secondary_dimension)
                fig = px.treemap(agg_df, path=path, values=agg_col)
            elif chart_type == 'funil': fig = px.funnel(agg_df, x=agg_col, y=dimension)
            elif chart_type == 'tabela':
                header_color = theme_colors.get('primary_color', '#1f77b4')
                fig = go.Figure(data=[go.Table(
                    header=dict(values=list(agg_df.columns), fill_color=header_color, align='left', font=dict(color='white')), 
                    cells=dict(values=[agg_df[col] for col in agg_df.columns], fill_color='#f0f2f6', align='left')
                )])
            
            if fig:
                fig = apply_chart_theme(fig, color_theme)
                fig.update_layout(title_text=None)
                if chart_config.get('y_axis_format') == 'hours':
                    fig.update_layout(yaxis_title=y_axis_title_text) if chart_type != 'barra_horizontal' else fig.update_layout(xaxis_title=y_axis_title_text)
                
                if chart_config.get('show_data_labels') and chart_type not in ['tabela', 'pizza', 'treemap']:
                    text_template = '%{value:.2f}h' if chart_config.get('y_axis_format') == 'hours' else '%{value:.2s}'
                    
                    if chart_type in ['barra', 'barra_horizontal']:
                        fig.update_traces(texttemplate=text_template, textposition='auto')
                    elif chart_type == 'linha_agregada':
                        fig.update_traces(texttemplate=text_template, textposition='top center')
                    elif chart_type == 'funil':
                        fig.update_traces(texttemplate=text_template, textposition='auto')

                if chart_config.get('show_as_percentage'):
                    if chart_type == 'pizza': fig.update_traces(texttemplate='%{value:.1f}%')
                    else: fig.update_layout(yaxis_ticksuffix="%")
                st.plotly_chart(fig, use_container_width=True, key=f"{chart_key}_agg")

        elif chart_type in ['linha', 'dispers√£o']:
            x, y = chart_config.get('x'), chart_config.get('y')
            size_by = chart_config.get('size_by')
            color_by = chart_config.get('color_by')

            if not x or not y:
                st.warning("Configura√ß√£o de gr√°fico X-Y inv√°lida: Eixos X e Y s√£o obrigat√≥rios.")
                return

            required_cols = [x, y]
            if size_by and size_by != "Nenhum": required_cols.append(size_by)
            if color_by and color_by != "Nenhum": required_cols.append(color_by)
            
            if not all(col in df.columns for col in required_cols):
                missing = [col for col in required_cols if col not in df.columns]
                st.warning(f"N√£o foi poss√≠vel renderizar o gr√°fico. Coluna(s) n√£o encontrada(s): {', '.join(missing)}")
                return

            plot_df = df_chart_filtered.copy().dropna(subset=required_cols)
            if plot_df.empty:
                st.warning("N√£o h√° dados para exibir com as colunas e filtros selecionados.")
                return

            x_axis_col_for_plotting = x 
            date_aggregation = chart_config.get('date_aggregation')
            if date_aggregation and date_aggregation != 'Nenhum' and x in plot_df.columns:
                plot_df[x] = pd.to_datetime(plot_df[x], errors='coerce')
                plot_df.dropna(subset=[x], inplace=True)

                if pd.api.types.is_datetime64_any_dtype(plot_df[x]):
                    freq_map = {'Dia': 'D', 'Semana': 'W-MON', 'M√™s': 'MS', 'Trimestre': 'QS', 'Ano': 'AS'}
                    freq = freq_map.get(date_aggregation)

                    if freq:
                        y_agg_func = chart_config.get('y_axis_aggregation', 'M√©dia').lower()
                        agg_map = {'soma': 'sum', 'm√©dia': 'mean'}
                        
                        grouping_cols = [pd.Grouper(key=x, freq=freq)]
                        if color_by and color_by != "Nenhum": grouping_cols.append(color_by)

                        agg_dict = {y: agg_map.get(y_agg_func, 'mean')}
                        if size_by and size_by != "Nenhum": agg_dict[size_by] = 'mean'

                        plot_df = plot_df.groupby(grouping_cols, as_index=False).agg(agg_dict)
                        plot_df = plot_df.sort_values(by=x)

                        x_axis_col_for_plotting = f"{x} ({date_aggregation})"
                        if date_aggregation == 'Dia':
                            plot_df[x_axis_col_for_plotting] = plot_df[x].dt.strftime('%Y-%m-%d')
                        elif date_aggregation == 'Semana':
                            plot_df[x_axis_col_for_plotting] = plot_df[x].dt.strftime('Semana %U (%Y)')
                        elif date_aggregation == 'M√™s':
                            plot_df[x_axis_col_for_plotting] = plot_df[x].dt.strftime('%Y-%m')
                        elif date_aggregation == 'Trimestre':
                            plot_df[x_axis_col_for_plotting] = plot_df[x].dt.year.astype(str) + '-T' + plot_df[x].dt.quarter.astype(str)
                        elif date_aggregation == 'Ano':
                            plot_df[x_axis_col_for_plotting] = plot_df[x].dt.year.astype(str)

            y_axis_title = chart_config.get('y_axis_title', y)
            if chart_config.get('y_axis_format') == 'hours' and y in plot_df.columns:
                plot_df[y] = pd.to_numeric(plot_df[y], errors='coerce') / 3600.0
                y_axis_title = y_axis_title.replace(y, f"{y} (horas)") if y in y_axis_title else f"{y} (horas)"
            
            plot_args = {
                "data_frame": plot_df, "x": x_axis_col_for_plotting, "y": y,
                "color": color_by if color_by and color_by != "Nenhum" else None,
                "text": y if chart_config.get('show_data_labels') else None,
            }

            fig_func = px.line if chart_type == 'linha' else px.scatter

            if chart_type == 'dispers√£o':
                size_col = size_by if size_by and size_by != "Nenhum" else None
                if size_col and size_col in plot_df.columns:
                    plot_df[size_col] = pd.to_numeric(plot_df[size_col], errors='coerce').dropna()
                    
                    original_rows = len(plot_df)
                    plot_df = plot_df[plot_df[size_col] >= 0].copy()
                    if len(plot_df) < original_rows:
                        st.caption(f"‚ÑπÔ∏è {original_rows - len(plot_df)} pontos de dados foram removidos da visualiza√ß√£o porque tinham valores negativos no campo de tamanho ('{size_col}').")
                    
                    plot_args['size'] = size_col
                    plot_args['data_frame'] = plot_df

            if plot_df.empty:
                st.warning("N√£o restaram dados para exibir ap√≥s a remo√ß√£o de valores inv√°lidos.")
                return

            fig = fig_func(**plot_args)
            fig = apply_chart_theme(fig, color_theme)
            
            if chart_config.get('show_data_labels'):
                text_template = '%{text:.2f}h' if chart_config.get('y_axis_format') == 'hours' else '%{text:.2s}'
                fig.update_traces(textposition='top center', texttemplate=text_template)
            
            fig.update_layout(title_text=None, xaxis_title=chart_config.get('x_axis_title', x), yaxis_title=y_axis_title)
            st.plotly_chart(fig, use_container_width=True, key=f"{chart_key}_xy")

        elif chart_type == 'indicator':
            # --- L√ìGICA DE RENDERIZA√á√ÉO ATUALIZADA ---
            theme_colors = COLOR_THEMES.get(color_theme, COLOR_THEMES[default_theme])
            if not isinstance(theme_colors, dict):
                theme_colors = COLOR_THEMES[default_theme]
            
            title_color = theme_colors.get('title_color', '#3D3D3D')
            number_color = theme_colors.get('primary_color', '#0068C9')
            delta_color = theme_colors.get('secondary_color', '#83C9FF')
            
            # Pega as configura√ß√µes de formata√ß√£o do gr√°fico
            decimal_places = int(chart_config.get('kpi_decimal_places', 2))
            format_as_pct = chart_config.get('kpi_format_as_percentage', False)
            valueformat = f".{decimal_places}f"
            suffix = "%" if format_as_pct else ""
            
            main_value = None
            baseline = None
            fig = None
            
            # Calcula os valores brutos (main_value e baseline)
            if chart_config.get('source_type') == 'jql':
                from jira_connector import get_jql_issue_count
                jql_a = chart_config.get('jql_a', '')
                if not jql_a.strip():
                    st.warning("A Consulta JQL 1 (Valor A) √© obrigat√≥ria e est√° vazia.")
                    return
                val_a = get_jql_issue_count(st.session_state.jira_client, jql_a)
                if not isinstance(val_a, (int, float)):
                    st.error(f"Erro ao processar a Consulta JQL 1 (Valor A): {val_a}")
                    return
                val_b = None
                jql_b = chart_config.get('jql_b', '')
                if jql_b.strip():
                    val_b_raw = get_jql_issue_count(st.session_state.jira_client, jql_b)
                    if isinstance(val_b_raw, (int, float)): val_b = val_b_raw
                    else: st.warning(f"Aviso na Consulta JQL 2 (Valor B): {val_b_raw}")
                main_value = val_a
                op = chart_config.get('jql_operation')
                if op != "Nenhuma" and val_b is not None:
                    if op == "Dividir (A / B)": main_value = val_a / val_b if val_b != 0 else 0
                    elif op == "Somar (A + B)": main_value = val_a + val_b
                    elif op == "Subtrair (A - B)": main_value = val_a - val_b
                    elif op == "Multiplicar (A * B)": main_value = val_a * val_b
                
                jql_baseline = chart_config.get('jql_baseline', '')
                if jql_baseline.strip():
                    baseline_raw = get_jql_issue_count(st.session_state.jira_client, jql_baseline)
                    if isinstance(baseline_raw, (int, float)): baseline = baseline_raw
                    else: st.warning(f"Aviso na Consulta da Linha de Base (Valor C): {baseline_raw}")
            
            else: # source_type == 'visual'
                main_value = calculate_kpi_value(chart_config.get('num_op'), chart_config.get('num_field'), df_chart_filtered)
                
                if chart_config.get('use_baseline', False):
                    baseline = calculate_kpi_value(
                        chart_config.get('base_op'), 
                        chart_config.get('base_field'), 
                        df_chart_filtered
                    )
                if chart_config.get('use_den'):
                    denominator = calculate_kpi_value(chart_config.get('den_op'), chart_config.get('den_field'), df_chart_filtered)
                    if denominator is not None and denominator != 0:
                        main_value = (main_value / denominator)
                        if baseline is not None:
                            baseline = (baseline / denominator)
                    else:
                        main_value = 0
                        baseline = 0 if baseline is not None else None

            # Aplica a formata√ß√£o percentual (se ativada)
            if format_as_pct:
                if isinstance(main_value, (int, float)):
                    main_value *= 100
                if isinstance(baseline, (int, float)):
                    baseline *= 100
            
            # Constr√≥i a figura final com a formata√ß√£o
            fig = go.Figure(go.Indicator(
                mode="number" + ("+delta" if baseline is not None else ""),
                value=main_value,
                title={"text": chart_config.get('title'), "font": {"color": title_color}},
                number={"font": {"color": number_color}, "valueformat": valueformat, "suffix": suffix},
                delta={'reference': baseline, "font": {"color": delta_color}, "valueformat": valueformat} if baseline is not None else None
            ))
            
            if fig:
                fig.update_layout(margin=dict(l=0, r=0, t=40, b=10), height=150, paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(0,0,0,0)')
                st.plotly_chart(fig, use_container_width=True, key=f"{chart_key}_indicator")

        elif chart_type == 'pivot_table':
            rows = chart_config.get('rows'); cols = chart_config.get('columns'); values = chart_config.get('values'); aggfunc = chart_config.get('aggfunc', 'Soma').lower()
            agg_map = {'soma': 'sum', 'm√©dia': 'mean', 'contagem': 'count'}
            if rows and values:
                pivot_df = pd.pivot_table(df_chart_filtered, values=values, index=rows, columns=cols, aggfunc=agg_map.get(aggfunc, 'sum')).reset_index()

                theme_colors = COLOR_THEMES.get(color_theme, COLOR_THEMES[default_theme])
                if not isinstance(theme_colors, dict):
                    theme_colors = COLOR_THEMES[default_theme]
                header_color = theme_colors.get('primary_color', '#1f77b4')
                fig = go.Figure(data=[go.Table(
                    header=dict(values=list(pivot_df.columns), fill_color=header_color, align='left', font=dict(color='white')), 
                    cells=dict(values=[pivot_df[col] for col in pivot_df.columns], fill_color='#f0f2f6', align='left')
                )])
                st.plotly_chart(fig, use_container_width=True, key=f"{chart_key}_pivot")
            else: 
                st.warning("Para a Tabela Din√¢mica, 'Linhas' e 'Valores' s√£o obrigat√≥rios.")

        elif chart_type == 'metric_with_chart':
            fig_func_map = {'linha': px.line, '√°rea': px.area, 'barra': px.bar}
            title = chart_config.get('title')
            dimension = chart_config.get('mc_dimension')
            measure = chart_config.get('mc_measure')
            chart_type_internal = chart_config.get('mc_chart_type', 'Linha').lower()
            main_value_agg = chart_config.get('mc_main_value_agg')
            delta_agg = chart_config.get('mc_delta_agg')

            if not dimension or not measure:
                st.warning("Configura√ß√£o de M√©trica inv√°lida. Dimens√£o e Medida s√£o obrigat√≥rias.")
                return

            measure_col_for_plotting = measure
            if measure == "Contagem de Issues":
                df_chart = df_chart_filtered.groupby(dimension).size().reset_index(name="Contagem de Issues")
                df_chart = df_chart.sort_values(by=dimension)
                measure_col_for_plotting = "Contagem de Issues"
            else:
                df_chart = df_chart_filtered.sort_values(by=dimension).dropna(subset=[measure])
            
            if df_chart.empty:
                 st.warning("N√£o h√° dados para exibir na M√©trica com Gr√°fico.")
                 st.metric(label=title, value="N/A")
                 return

            chart_data_values = df_chart[measure_col_for_plotting].tolist()
            
            main_value = 0
            if main_value_agg == "√öltimo valor da s√©rie":
                main_value = chart_data_values[-1] if chart_data_values else 0
            elif main_value_agg == "Soma de todos os valores":
                main_value = sum(chart_data_values)
            elif main_value_agg == "M√©dia de todos os valores":
                main_value = sum(chart_data_values) / len(chart_data_values) if chart_data_values else 0

            delta = None
            if len(chart_data_values) > 1:
                if delta_agg == "Varia√ß√£o (√∫ltimo - primeiro)":
                    delta = chart_data_values[-1] - chart_data_values[0]
                elif delta_agg == "Varia√ß√£o (√∫ltimo - pen√∫ltimo)":
                    delta = chart_data_values[-1] - chart_data_values[-2]

            st.metric(
                label=title,
                value=f"{main_value:,.2f}",
                delta=f"{delta:,.2f}" if delta is not None else None
            )

            spark_df = pd.DataFrame({
                dimension: df_chart[dimension],
                measure_col_for_plotting: chart_data_values
            })

            fig = fig_func_map[chart_type_internal](spark_df, x=dimension, y=measure_col_for_plotting)

            fig.update_layout(
                showlegend=False,
                xaxis=dict(visible=False, showgrid=False),
                yaxis=dict(visible=False, showgrid=False),
                margin=dict(l=0, r=0, t=0, b=0),
                height=60,
                plot_bgcolor='rgba(0,0,0,0)',
                paper_bgcolor='rgba(0,0,0,0)',
            )
            
            if chart_type_internal in ['linha', '√°rea']:
                fig.update_traces(line=dict(width=2.5))

            st.plotly_chart(fig, use_container_width=True, key=f"{chart_key}_sparkline")

    except Exception as e:
        import traceback
        title = chart_config.get('title', 'Desconhecido') if isinstance(chart_config, dict) else 'Desconhecido'
        st.error(f"Ocorreu um erro ao renderizar o gr√°fico '{title}'.")
        with st.expander("Ver detalhes t√©cnicos do erro"):
            st.error(f"**Tipo de Erro:** {type(e).__name__}")
            st.error(f"**Mensagem:** {e}")
            st.code(traceback.format_exc())
        with st.expander("Ver dados do gr√°fico com erro"):
            try:
                st.json(chart_config)
            except:
                st.write(chart_config)

def combined_dimension_ui(df, categorical_cols, date_cols, key_suffix=""):
    st.markdown("###### **Criar Dimens√£o Combinada**")
    c1, c2 = st.columns(2)
    dim1 = c1.selectbox("Campo 1", options=categorical_cols + date_cols, key=f"dim1_{key_suffix}")
    dim2 = c2.selectbox("Campo 2", options=[c for c in categorical_cols + date_cols if c != dim1], key=f"dim2_{key_suffix}")
    new_dim_name = f"{dim1} & {dim2}"
    df_copy = df.copy()
    df_copy[new_dim_name] = df_copy[dim1].astype(str) + " - " + df_copy[dim2].astype(str)
    st.success(f"Dimens√£o '{new_dim_name}' criada para a pr√©-visualiza√ß√£o.")
    return new_dim_name, df_copy

def get_start_end_states(project_key):
    project_config = get_project_config(project_key) or {}
    status_mapping = project_config.get('status_mapping', {})
    global_configs = get_global_configs()
    initial_states = status_mapping.get('initial', global_configs.get('initial_states', []))
    done_states = status_mapping.get('done', global_configs.get('done_states', []))
    return initial_states, done_states

def find_date_for_status(changelog, target_statuses, default=None):
    for history in changelog.histories:
        for item in history.items:
            if item.field == 'status' and item.toString in target_statuses:
                return pd.to_datetime(history.created).replace(tzinfo=None)
    return default

def convert_dates_in_filters(filters):
    processed_filters = []
    for f in filters:
        new_filter = f.copy()
        value = new_filter.get('value')
        if isinstance(value, (date, datetime)):
            new_filter['value'] = value.isoformat()
        elif isinstance(value, (list, tuple)) and any(isinstance(v, (date, datetime)) for v in value):
            new_filter['value'] = [v.isoformat() if isinstance(v, (date, datetime)) else v for v in value]
        processed_filters.append(new_filter)
    return processed_filters

def clean_html(raw_html):
    if not isinstance(raw_html, str):
        return str(raw_html)
    cleanr = re.compile('<.*?>')
    cleantext = re.sub(cleanr, '', raw_html)
    return html.unescape(cleantext)

def clean_text(text):
    """Remove caracteres que n√£o s√£o suportados pela fonte padr√£o do FPDF."""
    if text is None:
        return ''
    # Normaliza para decompor caracteres acentuados e remove caracteres de controle
    text = ''.join(c for c in unicodedata.normalize('NFKD', str(text)) if unicodedata.category(c) != 'Mn' and c.isprintable())
    return text

class PDF(FPDF):
    """Classe FPDF customizada para ter cabe√ßalho e rodap√© com logo e t√≠tulo."""
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.os_title = "Ordem de Servi√ßo"

    def header(self):
        try:
            # Caminho corrigido para a pasta 'images' no mesmo n√≠vel da pasta 'pages'
            logo_path = str(Path(__file__).resolve().parent.parent / "images" / "logo.png")
            self.image(logo_path, 10, 8, 25)
        except Exception as e:
            print(f"Erro ao carregar o logo: {e}")
            self.set_xy(10, 8)
            self.set_font('Roboto', 'I', 8)
            self.cell(25, 10, '[Logo]', 0, 0, 'L')

        self.set_font('Roboto', 'B', 15)
        self.cell(0, 10, clean_text(self.os_title), 0, 0, 'C')
        self.ln(20)

    def footer(self):
        self.set_y(-15)
        self.set_font('Roboto', 'I', 8)
        self.cell(0, 10, f'P√°gina {self.page_no()}', 0, 0, 'C')

def render_pdf_field(pdf, field_info, value, width):
    """Renderiza o valor de um campo no PDF, tratando diferentes tipos."""
    pdf.set_font('Roboto', '', 10)
    field_type = field_info.get('field_type')

    if value is None or value == '' or (isinstance(value, list) and not value):
        pdf.multi_cell(width, 6, "-")
        return

    if field_type == "Tabela" and isinstance(value, list) and value:
        pdf.ln(2)
        if not value[0]: return
        headers = value[0].keys()
        pdf.set_font('Roboto', 'B', 9)
        col_width = (width / len(headers)) - 1 if len(headers) > 0 else width
        for h in headers:
            pdf.cell(col_width, 6, clean_text(h), 1, 0, 'C')
        pdf.ln()
        pdf.set_font('Roboto', '', 8)
        for row in value:
            for h in headers:
                pdf.cell(col_width, 6, clean_text(row.get(h)), 1, 0, 'L')
            pdf.ln()
    elif field_type == "Toggle (Sim/N√£o)":
        display_val = "Sim" if value else "N√£o"
        pdf.multi_cell(width, 6, display_val)
    elif isinstance(value, list):
        display_val = ", ".join(map(str, value))
        pdf.multi_cell(width, 6, clean_text(display_val))
    else:
        pdf.multi_cell(width, 6, clean_text(value))

def create_os_pdf(data, os_title=None):
    """
    Gera um PDF para a Ordem de Servi√ßo, com o alinhamento de texto corrigido
    e a tabela de itens complexa.
    """
    pdf = PDF()
    
    if os_title:
        pdf.os_title = clean_text(os_title)
    else:
        pdf.os_title = f"Ordem de Servi√ßo: {clean_text(data.get('layout_name', 'N/A'))}"

    base_dir = Path(__file__).resolve().parent
    font_dir = base_dir / "fonts"
    pdf.add_font('Roboto', '', str(font_dir / "Roboto-Regular.ttf"))
    pdf.add_font('Roboto', 'B', str(font_dir / "Roboto-Bold.ttf"))
    pdf.add_font('Roboto', 'I', str(font_dir / "Roboto-Italic.ttf"))
    
    pdf.add_page()
    pdf.set_font('Roboto', 'B', 12)
    pdf.cell(0, 10, 'Detalhes da Ordem de Servi√ßo', 0, 1, 'L')
    pdf.ln(2)

    layout_fields = data.get('custom_fields_layout', [])
    custom_data = data.get('custom_fields', {})
    
    i = 0
    while i < len(layout_fields):
        field1 = layout_fields[i]
        
        field_value_dict = custom_data.get(field1['field_name'], {})
        field_actual_value = field_value_dict.get('value') if isinstance(field_value_dict, dict) else field_value_dict
        
        est_height = 15
        if isinstance(field_actual_value, str) and field1['field_type'] == 'Texto Longo':
            est_height = (len(field_actual_value) / 80) * 8 + 20
        elif isinstance(field_actual_value, list) and field1['field_type'] == 'Tabela':
            est_height = len(field_actual_value) * 10 + 25
        if pdf.get_y() + est_height > 270:
            pdf.add_page()
            
        is_two_col = field1.get('two_columns', False)
        next_field_is_two_col = (i + 1 < len(layout_fields)) and layout_fields[i+1].get('two_columns', False)

        line_height = 6

        # --- L√ìGICA DE ALINHAMENTO CORRIGIDA ---
        if is_two_col and next_field_is_two_col:
            field2 = layout_fields[i+1]
            y_start = pdf.get_y()
            half_width = (pdf.w - pdf.l_margin - pdf.r_margin) / 2 - 2
            col2_start_x = pdf.l_margin + half_width + 4

            # --- Coluna 1 ---
            pdf.set_font('Roboto', 'B', 11)
            pdf.multi_cell(half_width, line_height, clean_text(field1['field_name']), 0, 'L')
            pdf.set_x(pdf.l_margin) # Garante que o valor comece no in√≠cio da coluna
            render_pdf_field(pdf, field1, field_actual_value, width=half_width)
            y_after_col1 = pdf.get_y()

            # --- Coluna 2 ---
            pdf.set_xy(col2_start_x, y_start) # Move o cursor para o in√≠cio da segunda coluna
            field2_value_dict = custom_data.get(field2['field_name'], {})
            field2_actual_value = field2_value_dict.get('value') if isinstance(field2_value_dict, dict) else field2_value_dict
            
            pdf.set_font('Roboto', 'B', 11)
            pdf.multi_cell(half_width, line_height, clean_text(field2['field_name']), 0, 'L')
            pdf.set_x(col2_start_x) # Garante que o valor comece no in√≠cio da coluna 2
            render_pdf_field(pdf, field2, field2_actual_value, width=half_width)
            y_after_col2 = pdf.get_y()

            # --- Finaliza a linha ---
            pdf.set_y(max(y_after_col1, y_after_col2))
            pdf.ln(4)
            i += 2
        else:
            # Renderiza o campo de coluna √∫nica
            full_width = pdf.w - pdf.l_margin - pdf.r_margin
            pdf.set_font('Roboto', 'B', 11)
            pdf.multi_cell(full_width, line_height, clean_text(field1['field_name']), 0, 'L')
            pdf.set_x(pdf.l_margin) # Garante o alinhamento para o valor
            render_pdf_field(pdf, field1, field_actual_value, width=full_width)
            pdf.ln(4)
            i += 1
        # --- FIM DA CORRE√á√ÉO ---
            
    items = data.get('items')
    totals = data.get('items_totals')
    currency_name = data.get('currency_name', 'Moeda')

    if items:
        if pdf.get_y() > 200: pdf.add_page()
        pdf.ln(10)
        pdf.set_font('Roboto', 'B', 12)
        pdf.cell(0, 10, 'Itens do Cat√°logo', 0, 1, 'L')
        pdf.ln(2)

        page_width = pdf.w - 2 * pdf.l_margin
        col_widths = {"id": page_width * 0.1, "desc": page_width * 0.35, "qtd": page_width * 0.1, "val": page_width * 0.15, "total": page_width * 0.15, "brl": page_width * 0.15}
        
        pdf.set_font('Roboto', 'B', 9)
        pdf.cell(col_widths["id"], 7, 'Item ID', 1, 0, 'C')
        pdf.cell(col_widths["desc"], 7, 'Descri√ß√£o', 1, 0, 'C')
        pdf.cell(col_widths["qtd"], 7, 'Qtde. Itens', 1, 0, 'C')
        pdf.cell(col_widths["val"], 7, f'Valor ({currency_name})', 1, 0, 'C')
        pdf.cell(col_widths["total"], 7, f'Total ({currency_name})', 1, 0, 'C')
        pdf.cell(col_widths["brl"], 7, 'Valor (R$)', 1, 1, 'C')

        pdf.set_font('Roboto', '', 8)
        for item in items:
            desc_text = clean_text(item.get('Item', ''))
            
            lines_desc = pdf.multi_cell(col_widths["desc"], 5, desc_text, 0, 'L', split_only=True)
            cell_height = max(5 * len(lines_desc), 5) 

            if pdf.get_y() + cell_height > 277: 
                pdf.add_page()
                pdf.set_font('Roboto', 'B', 9)
                pdf.cell(col_widths["id"], 7, 'Item ID', 1, 0, 'C')
                pdf.cell(col_widths["desc"], 7, 'Descri√ß√£o', 1, 0, 'C')
                pdf.cell(col_widths["qtd"], 7, 'Qtde. Itens', 1, 0, 'C')
                pdf.cell(col_widths["val"], 7, f'Valor ({currency_name})', 1, 0, 'C')
                pdf.cell(col_widths["total"], 7, f'Total ({currency_name})', 1, 0, 'C')
                pdf.cell(col_widths["brl"], 7, 'Valor (R$)', 1, 1, 'C')
                pdf.set_font('Roboto', '', 8)

            x_start, y_start = pdf.get_x(), pdf.get_y()

            pdf.multi_cell(col_widths["id"], cell_height, str(item.get('ID do Item', '')), 1, 'C')
            pdf.set_xy(x_start + col_widths["id"], y_start)
            pdf.multi_cell(col_widths["desc"], 5, desc_text, 1, 'L')
            
            pdf.set_xy(x_start + col_widths["id"] + col_widths["desc"], y_start)
            
            pdf.cell(col_widths["qtd"], cell_height, str(item.get('Qtde. Itens', '')), 1, 0, 'C')
            pdf.cell(col_widths["val"], cell_height, str(item.get('Valor', '')), 1, 0, 'C')
            pdf.cell(col_widths["total"], cell_height, str(item.get('Total Currency', '')), 1, 0, 'C')
            
            brl_value = item.get('Valor (R$)', 0)
            formatted_brl = f"R$ {brl_value:,.2f}".replace(",", "X").replace(".", ",").replace("X", ".")
            pdf.cell(col_widths["brl"], cell_height, formatted_brl, 1, 1, 'R')

        if totals:
            pdf.set_font('Roboto', 'B', 9)
            total_currency = totals.get('TOTAL_CURRENCY', 0)
            total_brl = totals.get('TOTAL_BRL', 0)
            formatted_total_brl = f"R$ {total_brl:,.2f}".replace(",", "X").replace(".", ",").replace("X", ".")
            
            total_label_width = sum(col_widths.values()) - col_widths["total"] - col_widths["brl"]
            pdf.cell(total_label_width, 7, 'TOTAL', 1, 0, 'R')
            pdf.cell(col_widths["total"], 7, str(round(total_currency, 2)), 1, 0, 'C')
            pdf.cell(col_widths["brl"], 7, formatted_total_brl, 1, 1, 'R')

    if data.get('assinantes'):
        if pdf.get_y() > 220: pdf.add_page()
        pdf.ln(10)
        pdf.set_font('Roboto', 'B', 12)
        pdf.cell(0, 10, 'Assinaturas', 0, 1, 'L')
        pdf.ln(15)
        for assinante in data['assinantes']:
            if assinante.get('Nome') and assinante.get('Papel'):
                if pdf.get_y() > 250: pdf.add_page(); pdf.ln(10)
                pdf.cell(0, 8, "___________________________________________", 0, 1, 'C')
                pdf.cell(0, 8, clean_text(f"{assinante['Nome']}"), 0, 1, 'C')
                pdf.cell(0, 8, clean_text(f"({assinante['Papel']})"), 0, 1, 'C')
                pdf.ln(10)
    
    return bytes(pdf.output(dest='S'))

def create_dashboard_pdf(dashboard_name, charts_by_tab, df):
    """Gera um PDF do dashboard, com gr√°ficos como imagens."""
    pdf = PDF()
    pdf.os_title = f"Dashboard: {dashboard_name}"

    base_dir = Path(__file__).resolve().parent
    font_dir = base_dir / "fonts"
    pdf.add_font('Roboto', '', str(font_dir / "Roboto-Regular.ttf"))
    pdf.add_font('Roboto', 'B', str(font_dir / "Roboto-Bold.ttf"))

    pdf.add_page()

    for tab_name, charts in charts_by_tab.items():
        if not charts: continue
        if pdf.page_no() > 1 or pdf.get_y() > 40: pdf.add_page()

        pdf.set_font('Roboto', 'B', 18)
        pdf.cell(0, 10, f"Aba: {tab_name}", 0, 1, 'L')
        pdf.ln(5)

        for chart_config in charts:
            pdf.set_font('Roboto', 'B', 12)
            pdf.multi_cell(0, 8, f"üìä {chart_config.get('title', 'Gr√°fico sem t√≠tulo')}", 0, 'L')

            try:
                fig = render_chart(chart_config, df, return_fig=True)
                if fig:
                    img_bytes = fig.to_image(format="png", scale=2, width=800, height=450)
                    img_file = io.BytesIO(img_bytes)

                    if pdf.get_y() + 80 > 297: pdf.add_page()
                    pdf.image(img_file, w=180)
                    pdf.ln(10)
                else:
                    pdf.set_font('Roboto', '', 10)
                    pdf.set_text_color(255, 0, 0)
                    pdf.multi_cell(0, 5, "Nao foi possivel gerar uma imagem para este tipo de grafico.")
                    pdf.set_text_color(0, 0, 0)
                    pdf.ln(5)
            except Exception as e:
                pdf.set_font('Roboto', '', 10)
                pdf.set_text_color(255, 0, 0)
                error_type = type(e).__name__
                safe_error_message = f"Falha ao renderizar o grafico. Tipo de erro: {error_type}."
                pdf.multi_cell(0, 5, safe_error_message)
                pdf.set_text_color(0, 0, 0)
                pdf.ln(5)

    return pdf.output(dest='S').encode('latin-1')

def summarize_chart_data(chart_config, df):
    """Gera um resumo em texto dos dados de um √∫nico gr√°fico."""
    title = chart_config.get('title', 'um gr√°fico')
    chart_type = chart_config.get('type')

    try:
        df_to_render = apply_filters(df, chart_config.get('filters', []))

        if chart_type == 'indicator':
            if chart_config.get('source_type') == 'jql':
                return f"O indicador '{title}' √© calculado com uma consulta JQL personalizada."
            else:
                numerator = calculate_kpi_value(chart_config.get('num_op'), chart_config.get('num_field'), df_to_render)
                value = numerator
                if chart_config.get('use_den'):
                    denominator = calculate_kpi_value(chart_config.get('den_op'), chart_config.get('den_field'), df_to_render)
                    if denominator is not None and denominator != 0:
                        value = (numerator / denominator) * 100
                    else:
                        value = 0
                if value is not None and pd.notna(value):
                    return f"O indicador '{title}' mostra o valor de {value:.1f}."
                else:
                    return f"O indicador '{title}' n√£o p√¥de ser calculado (N/A)."

        elif chart_type in ['barra', 'pizza']:
            dimension = chart_config.get('dimension'); measure = chart_config.get('measure'); agg = chart_config.get('agg', 'Soma')
            if not dimension or not measure: return None
            if measure == 'Contagem de Issues':
                summary_df = df_to_render.groupby(dimension).size().nlargest(5)
                return f"No gr√°fico '{title}', a contagem de issues por '{dimension}' revela que os 5 maiores grupos s√£o: {', '.join([f'{idx} ({val})' for idx, val in summary_df.items()])}."
            else:
                summary_df = df_to_render.groupby(dimension)[measure].agg(agg.lower()).nlargest(5)
                return f"No gr√°fico '{title}', a {agg.lower()} de '{measure}' por '{dimension}' revela que os 5 maiores grupos s√£o: {', '.join([f'{idx} ({val:.1f})' for idx, val in summary_df.items()])}."

        elif chart_type == 'linha':
            x_col, y_col = chart_config['x'], chart_config['y']
            plot_df = df_to_render.dropna(subset=[x_col, y_col])
            if len(plot_df) > 2:
                X = np.array(range(len(plot_df))).reshape(-1, 1); y = plot_df[y_col]
                model = LinearRegression().fit(X, y)
                trend = "de subida" if model.coef_[0] > 0 else "de descida"
                return f"O gr√°fico de linha '{title}' mostra '{y_col}' ao longo de '{x_col}', com uma tend√™ncia geral {trend}."

        return f"Dados para o gr√°fico '{title}' do tipo {chart_type}."
    except Exception:
        return f"N√£o foi poss√≠vel processar os dados para o gr√°fico '{title}'."

# --- FUN√á√ïES DE IA ---
def _get_ai_client_and_model(provider, user_data):
    """Fun√ß√£o auxiliar para configurar e retornar o cliente de IA correto."""
    if user_data and user_data.get('role') == 'admin':
        with st.expander("üîç Dados do Perfil (Depura√ß√£o)", expanded=False):
            st.info("Verifique se a chave correta (Gemini ou OpenAI) est√° presente aqui.")
            st.json(user_data)

    api_key_encrypted = None
    if provider == "Google Gemini":
        api_key_encrypted = user_data.get('encrypted_gemini_key')
        if not api_key_encrypted:
            st.warning("Nenhuma chave de API do Gemini configurada.", icon="üîë")
            st.page_link("pages/9_üë§_Minha_Conta.py", label="Configurar Chave de IA Agora", icon="ü§ñ")
            return None
        try:
            api_key = decrypt_token(api_key_encrypted)
            genai.configure(api_key=api_key)
            model_name = user_data.get('ai_model_preference', 'gemini-flash-latest')
            return genai.GenerativeModel(model_name)
        except Exception as e:
            st.error(f"Erro com a API do Gemini: {e}"); return None

    elif provider == "OpenAI (ChatGPT)":
        api_key_encrypted = user_data.get('encrypted_openai_key')
        if not api_key_encrypted:
            st.warning("Nenhuma chave de API da OpenAI configurada.", icon="üîë")
            st.page_link("pages/9_üë§_Minha_Conta.py", label="Configurar Chave de IA Agora", icon="ü§ñ")
            return None
        try:
            api_key = decrypt_token(api_key_encrypted)
            return openai.OpenAI(api_key=api_key)
        except Exception as e:
            st.error(f"Erro com a API da OpenAI: {e}"); return None
    return None

def get_ai_insights(project_name, chart_summaries, provider):
    """Chama a API de IA preferida do utilizador para gerar insights do dashboard."""
    user_data = find_user(st.session_state['email'])
    model_client = _get_ai_client_and_model(provider, user_data)
    if not model_client: return None

    prompt = f"""
    Aja como um Analista de Neg√≥cios especialista em projetos de software e metodologias √°geis.
    O seu trabalho √© analisar os dados de um dashboard do Jira para o projeto "{project_name}" e fornecer um resumo executivo em portugu√™s.

    Aqui est√£o os dados resumidos de cada gr√°fico no dashboard:
    {chr(10).join(f"- {s}" for s in chart_summaries if s)}

    Com base nestes dados, gere uma an√°lise concisa e acion√°vel. A sua resposta deve ser formatada em Markdown e dividida nas seguintes sec√ß√µes:
    1.  **üéØ Pontos Fortes:** O que os dados indicam que est√° a correr bem? Seja espec√≠fico.
    2.  **‚ö†Ô∏è Pontos de Aten√ß√£o:** Onde podem estar os riscos, gargalos ou desvios? Aponte as m√©tricas preocupantes.
    3.  **üöÄ Recomenda√ß√µes:** Sugira 1 a 2 a√ß√µes pr√°ticas que a equipa ou o gestor do projeto poderiam tomar com base nesta an√°lise.
    """

    try:
        if provider == "Google Gemini":
            response = model_client.generate_content(prompt)
            return response.text
        else: # OpenAI
            response = model_client.chat.completions.create(model="gpt-4o", messages=[{"role": "user", "content": prompt}])
            return response.choices[0].message.content
    except openai.RateLimitError:
        st.error(
            """
            **Sua quota de utiliza√ß√£o da API da OpenAI foi excedida.** üòü
            Isto geralmente acontece quando os cr√©ditos gratuitos expiram ou o seu limite de fatura√ß√£o √© atingido.
            **O que fazer?**
            1. Aceda ao seu painel da [OpenAI Platform](https://platform.openai.com/account/billing/overview).
            2. Verifique a sua sec√ß√£o de **"Billing" (Fatura√ß√£o)** para adicionar um m√©todo de pagamento ou aumentar os seus limites.
            Enquanto isso, voc√™ pode ir √† sua p√°gina **'Minha Conta'** e mudar o seu provedor de IA para o **Google Gemini**.
            """,
            icon="üí≥"
        )
        return None
    except openai.AuthenticationError:
        st.error("A sua chave de API da OpenAI √© inv√°lida ou foi revogada. Por favor, verifique-a na p√°gina 'Minha Conta'.", icon="üîë")
        return None
    except Exception as e:
        st.error(f"Ocorreu um erro inesperado com a API da OpenAI: {e}"); return None

def generate_chart_config_from_text(prompt, numeric_cols, categorical_cols, active_filters=None):
    """
    Usa a API de IA para gerar uma configura√ß√£o de gr√°fico e aplica os filtros ativos.
    """
    user_data = find_user(st.session_state['email'])
    provider = user_data.get('ai_provider_preference', 'Google Gemini')
    cleaned_response = ""

    model_client = _get_ai_client_and_model(provider, user_data)
    if not model_client:
        return None, "A sua chave de API n√£o est√° configurada ou √© inv√°lida."

    system_prompt = f"""
    Aja como um especialista em Business Intelligence. Sua tarefa √© converter um pedido em linguagem natural para um objeto JSON que define uma visualiza√ß√£o.

    **GLOSS√ÅRIO DE CONCEITOS:**
    * **Dimens√£o ('dimension'):** O campo para agrupar os dados (ex: "issues POR STATUS").
    * **Medida ('measure'):** O valor a ser calculado (ex: "a SOMA DO LEAD TIME").
    * **Eixo X ('x') / Eixo Y ('y'):** Usados para gr√°ficos n√£o agregados que comparam duas colunas diretamente.
    * **Filtros ('filters'):** Condi√ß√µes para limitar os dados (ex: "APENAS PARA O CLIENTE 'APEX'").
    * **R√≥tulos de Dados ('show_data_labels'):** `true` se o utilizador pedir para "mostrar valores" ou "exibir totais".

    **CAMPOS DISPON√çVEIS:**
    - Categ√≥ricos: {', '.join(categorical_cols)}
    - Num√©ricos: {', '.join(numeric_cols)}

    **REGRAS DE GERA√á√ÉO:**
    1.  **Identificar a Inten√ß√£o:**
        * Se o pedido compara duas colunas diretamente (ex: "cycle time vs data de conclus√£o"), gere um **Gr√°fico X-Y**.
        * Se o pedido agrega uma medida por uma dimens√£o (ex: "total de issues por status"), gere um **Gr√°fico Agregado**.
        * Se o pedido resulta num n√∫mero √∫nico (ex: "qual o total de issues?"), gere um **Indicador (KPI)**.

    2.  **Estruturas JSON de Exemplo:**
        * **Gr√°fico X-Y:** `{{"creator_type": "Gr√°fico X-Y", "type": "[dispers√£o|linha]", "x": "...", "y": "...", "title": "..."}}`
        * **Gr√°fico Agregado:** `{{"creator_type": "Gr√°fico Agregado", "type": "[barra|linha_agregada|pizza]", "dimension": "...", "measure": "...", "agg": "...", "title": "..."}}`
        * **KPI:** `{{"creator_type": "Indicador (KPI)", "type": "indicator", "style": "N√∫mero Grande", "title": "...", "num_op": "...", "num_field": "..."}}`

    3.  **Regras de Preenchimento:**
        * Para contagem, a 'measure' DEVE ser "Contagem de Issues" e o 'agg' DEVE ser "Contagem".
        * Preste aten√ß√£o a palavras-chave como "linha", "barras", "pizza" para definir o campo "type". Se nada for dito, use "barra".

    Responda APENAS com o objeto JSON.
    ---
    """
    
    full_prompt = f"{system_prompt}\n\n**TAREFA REAL:**\nPedido do Utilizador: \"{prompt}\""

    try:
        if provider == "Google Gemini":
            response = model_client.generate_content(full_prompt)
            match = re.search(r'\{.*\}', response.text, re.DOTALL)
            cleaned_response = match.group(0) if match else "{}"
        else: # OpenAI
            response = model_client.chat.completions.create(model="gpt-4o", messages=[{"role": "user", "content": full_prompt}], response_format={"type": "json_object"})
            cleaned_response = response.choices[0].message.content

        if not cleaned_response: return None, "A IA n√£o retornou uma resposta."

        chart_config = json.loads(cleaned_response)

        if not isinstance(chart_config, dict) or 'type' not in chart_config:
            return None, f"A IA retornou uma resposta inesperada. Resposta: {cleaned_response}"

        ia_filters = chart_config.get('filters', [])
        chart_config['filters'] = active_filters + ia_filters
        chart_config['id'] = str(uuid.uuid4())
        chart_config['source_type'] = 'visual'

        return chart_config, None
    except Exception as e:
        return None, f"Ocorreu um erro ao processar a resposta da IA: {e}"


def generate_risk_analysis_with_ai(project_name, metrics_summary):
    """
    Usa a API de IA preferida do utilizador para analisar um resumo de m√©tricas
    e gerar uma lista de descri√ß√µes de riscos potenciais.
    """
    user_data = find_user(st.session_state['email'])
    provider = user_data.get('ai_provider_preference', 'Google Gemini')
    
    model_client = _get_ai_client_and_model(provider, user_data)
    if not model_client:
        st.error("An√°lise de riscos indispon√≠vel. Verifique a configura√ß√£o da sua chave de IA.")
        return [f"Erro: Chave de IA para o provedor '{provider}' n√£o configurada."]

    prompt = f"""
    Aja como um Agile Coach especialista. Analise o seguinte resumo de m√©tricas do projeto "{project_name}":
    {metrics_summary}

    Com base nestes dados, identifique 2 a 3 riscos ou pontos de aten√ß√£o cr√≠ticos.
    A sua resposta deve ser uma lista de descri√ß√µes de riscos, formatada como um JSON array de strings.
    Exemplo de resposta: ["O Lead Time m√©dio est√° a aumentar, o que pode indicar gargalos no in√≠cio do fluxo.", "A baixa taxa de entregas no √∫ltimo m√™s sugere uma poss√≠vel sobrecarga da equipa ou bloqueios externos."]
    Responda APENAS com o JSON array.
    """

    try:
        if provider == "Google Gemini":
            response = model_client.generate_content(prompt)
            cleaned_response = response.text.strip().replace("```json", "").replace("```", "")
            return json.loads(cleaned_response)

        elif provider == "OpenAI (ChatGPT)":
            response = model_client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "Responda apenas com um JSON array de strings."},
                    {"role": "user", "content": prompt}
                ],
                response_format={"type": "json_object"}
            )
            return json.loads(response.choices[0].message.content)

    except Exception as e:
        st.error(f"Erro ao gerar an√°lise de riscos: {e}")
        return [f"Erro na comunica√ß√£o com a API: {e}"]

def generate_ai_risk_assessment(project_name, metrics_summary):
    """
    Usa a API de IA preferida do utilizador para analisar m√©tricas e gerar
    um n√≠vel de risco e uma lista de descri√ß√µes de riscos.
    """
    user_data = find_user(st.session_state['email'])
    provider = user_data.get('ai_provider_preference', 'Google Gemini')

    model_client = _get_ai_client_and_model(provider, user_data)
    if not model_client:
        return {"risk_level": "Erro", "risks": [f"Chave de IA para o provedor '{provider}' n√£o configurada."]}

    prompt = f"""
    Aja como um Gestor de Projetos S√™nior. Analise o seguinte resumo de m√©tricas do projeto "{project_name}":
    {metrics_summary}

    Com base nestes dados, fa√ßa o seguinte:
    1.  Classifique o N√≠vel de Risco geral do projeto como "Baixo", "Moderado", "Alto" ou "Cr√≠tico".
    2.  Identifique de 2 a 3 riscos ou pontos de aten√ß√£o cr√≠ticos que justificam essa classifica√ß√£o.

    A sua resposta deve ser um objeto JSON com a seguinte estrutura:
    {{
      "risk_level": "Seu N√≠vel de Risco aqui",
      "risks": [
        "Descri√ß√£o detalhada do primeiro risco.",
        "Descri√ß√£o detalhada do segundo risco."
      ]
    }}
    Responda APENAS com o objeto JSON.
    """

    try:
        if provider == "Google Gemini":
            response = model_client.generate_content(prompt)
            cleaned_response = response.text.strip().replace("```json", "").replace("```", "")
            return json.loads(cleaned_response)

        elif provider == "OpenAI (ChatGPT)":
            response = model_client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "Responda apenas com um objeto JSON v√°lido."},
                    {"role": "user", "content": prompt}
                ],
                response_format={"type": "json_object"}
            )
            return json.loads(response.choices[0].message.content)

    except Exception as e:
        st.error(f"Erro ao gerar an√°lise de riscos: {e}")
        return {"risk_level": "Erro", "risks": [f"Erro na comunica√ß√£o com a API: {e}"]}
    
def get_ai_rag_status(project_name, metrics_summary):
    """
    Usa a API de IA preferida do utilizador para analisar m√©tricas e determinar
    um status RAG para o projeto.
    """
    user_data = find_user(st.session_state['email'])
    provider = user_data.get('ai_provider_preference', 'Google Gemini')
    
    model_client = _get_ai_client_and_model(provider, user_data)
    if not model_client: 
        st.error("An√°lise indispon√≠vel. Verifique a configura√ß√£o da sua chave de IA.")
        return "‚ö™ Erro"

    prompt = f"""
    Aja como um Diretor de Projetos (PMO). Analise o seguinte resumo de m√©tricas do projeto "{project_name}":
    {metrics_summary}

    Com base nestes dados, classifique o status do projeto em UMA das seguintes quatro categorias:
    "üü¢ No prazo", "üü° Atraso moderado", "üî¥ Atrasado", "‚ö™ N√£o definido".

    Use o seguinte crit√©rio:
    - Se o percentual conclu√≠do for alto e o desvio de prazo for negativo ou pr√≥ximo de zero, o status √© "üü¢ No prazo".
    - Se o percentual conclu√≠do for m√©dio e o desvio de prazo for positivo, mas pequeno, o status √© "üü° Atraso moderado".
    - Se o percentual conclu√≠do for baixo e o desvio de prazo for significativamente positivo, o status √© "üî¥ Atrasado".
    - Se os dados forem insuficientes para uma conclus√£o, use "‚ö™ N√£o definido".

    Responda APENAS com a string da categoria escolhida, sem nenhuma outra palavra.
    """

    try:
        if provider == "Google Gemini":
            response = model_client.generate_content(prompt)
            return response.text.strip()

        elif provider == "OpenAI (ChatGPT)":
            response = model_client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "Responda apenas com a string da categoria escolhida."},
                    {"role": "user", "content": prompt}
                ]
            )
            return response.choices[0].message.content.strip()

    except Exception as e:
        st.error(f"Erro ao gerar status RAG: {e}")
        return "‚ö™ Erro"

def get_ai_forecast_analysis(project_name, scope_total, completed_pct, avg_velocity, trend_velocity, forecast_date_str):
    """Gera um resumo de forecast usando a IA configurada."""
    user_data = find_user(st.session_state['email'])
    provider = user_data.get('ai_provider_preference', 'Google Gemini')
    model_client = _get_ai_client_and_model(provider, user_data)
    if not model_client: return "An√°lise indispon√≠vel. Verifique a configura√ß√£o da sua chave de IA."

    metrics_summary = f"- Escopo Total: {scope_total}\n- Percentual Conclu√≠do: {completed_pct}%\n- Velocidade M√©dia: {avg_velocity:.1f}/semana\n- Velocidade de Tend√™ncia: {trend_velocity:.1f}/semana\n- Previs√£o de Conclus√£o: {forecast_date_str}"
    prompt = f"Aja como um Gestor de Projetos. Analise as m√©tricas do projeto '{project_name}':\n{metrics_summary}\n\nEscreva um par√°grafo de 'Resumo Executivo' a avaliar a sa√∫de, acelera√ß√£o e realismo da previs√£o de entrega."

    try:
        if provider == "Google Gemini":
            response = model_client.generate_content(prompt)
            return response.text
        else: # OpenAI
            response = model_client.chat.completions.create(model="gpt-4o", messages=[{"role": "user", "content": prompt}])
            return response.choices[0].message.content
    except Exception as e:
        return f"Erro ao gerar a an√°lise de forecast: {e}"

def get_ai_planning_analysis(project_name, remaining_work, remaining_weeks, required_throughput, trend_velocity, people_needed, current_team_size):
    """
    Usa a API de IA preferida do utilizador para analisar um cen√°rio de planeamento
    e gerar uma an√°lise de viabilidade, combinando a l√≥gica de prompt detalhada
    com a gest√£o de chaves centralizada.
    """
    user_data = find_user(st.session_state['email'])
    provider = user_data.get('ai_provider_preference', 'Google Gemini')

    # 1. Obt√©m o cliente de IA de forma segura atrav√©s da fun√ß√£o central
    model_client = _get_ai_client_and_model(provider, user_data)
    if not model_client:
        return "An√°lise indispon√≠vel. Verifique a configura√ß√£o da sua chave de IA."

    # 2. Constr√≥i o resumo das m√©tricas e o prompt detalhado
    metrics_summary = f"""
    - Trabalho Restante: {remaining_work}
    - Semanas Restantes at√© a meta: {remaining_weeks:.1f}
    - Vaz√£o (Throughput) Necess√°ria: {required_throughput:.1f} por semana
    - Vaz√£o de Tend√™ncia (performance recente): {trend_velocity:.1f} por semana
    - Pessoas Necess√°rias (estimativa): {people_needed}
    - Tamanho da Equipa Atual: {current_team_size}
    """

    prompt = f"""
    Aja como um Agile Coach S√™nior. Analise o seguinte cen√°rio de planeamento de entrega para o projeto "{project_name}":
    {metrics_summary}

    Com base nesta compara√ß√£o entre o necess√°rio e o hist√≥rico, escreva um par√°grafo de "An√°lise de Viabilidade". O seu texto deve ser conciso e focado em responder √†s seguintes perguntas:
    1.  O plano √© realista? Compare a "Vaz√£o Necess√°ria" com a "Vaz√£o de Tend√™ncia".
    2.  Quais s√£o os principais riscos se a vaz√£o necess√°ria for muito maior que a tend√™ncia? (Ex: risco de burnout, queda na qualidade).
    3.  Com base na estimativa de "Pessoas Necess√°rias" vs. o tamanho atual da equipa, qual √© a sua recomenda√ß√£o? (Ex: "o plano √© vi√°vel com a equipa atual", "o plano exige recursos adicionais", etc.).

    Seja direto e use uma linguagem clara e profissional.
    """

    # 3. Chama a API correta e retorna a resposta
    try:
        if provider == "Google Gemini":
            response = model_client.generate_content(prompt)
            return response.text
        elif provider == "OpenAI (ChatGPT)":
            response = model_client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "Aja como um Agile Coach S√™nior."},
                    {"role": "user", "content": prompt}
                ]
            )
            return response.choices[0].message.content
    except Exception as e:
        st.error(f"Erro ao gerar a an√°lise de planeamento: {e}")
        return "N√£o foi poss√≠vel gerar a an√°lise de planeamento."

def get_field_value(issue, field_config):
    """
    Fun√ß√£o inteligente que extrai o valor de qualquer campo do Jira,
    independentemente do seu tipo (texto, lista, objeto, etc.).
    """
    field_id = field_config.get('id')
    if not field_id:
        return None

    value = getattr(issue.fields, field_id, None)

    if value is None:
        return None

    # L√≥gica para os diferentes tipos de objeto do Jira
    if hasattr(value, 'displayName'): return value.displayName # Para campos de Utilizador
    if hasattr(value, 'value'): return value.value           # Para campos de Lista de Sele√ß√£o
    if hasattr(value, 'name'): return value.name             # Para campos de Objeto Simples (Status, Priority)
    if isinstance(value, list):
        return ', '.join([getattr(v, 'name', str(v)) for v in value]) # Para listas

    # Se for um tipo simples (texto, n√∫mero, data)
    return str(value).split('T')[0]

def send_email_with_attachment(to_address, subject, body, attachment_bytes=None, attachment_filename=None):
    """
    Fun√ß√£o central para enviar e-mails, com base no provedor
    configurado pelo utilizador na sua conta. Trata o corpo do e-mail como HTML.
    """
    smtp_configs = st.session_state.get('smtp_configs')

    if not smtp_configs or not smtp_configs.get('provider'):
        print("DEBUG: Nenhuma configura√ß√£o de SMTP encontrada na sess√£o.")
        return False, "Falha: Configura√ß√µes de SMTP n√£o carregadas na sess√£o."

    provider = smtp_configs.get('provider')

    if provider == 'SendGrid':
        try:
            api_key_encrypted = smtp_configs.get('api_key_encrypted') or smtp_configs.get('api_key')
            if not api_key_encrypted:
                return False, "Chave de API do SendGrid n√£o encontrada."

            api_key = decrypt_token(api_key_encrypted)
            sg = sendgrid.SendGridAPIClient(api_key)
            from_email = smtp_configs['from_email']

            message = Mail(from_email=from_email, to_emails=to_address, subject=subject, html_content=body)

            if attachment_bytes and attachment_filename:
                encoded_file = base64.b64encode(attachment_bytes).decode()
                attachedFile = Attachment(
                    FileContent(encoded_file),
                    FileName(attachment_filename),
                    FileType('application/pdf'),
                    Disposition('attachment')
                )
                message.attachment = attachedFile

            response = sg.send(message)
            print(f"DEBUG: Resposta do SendGrid - Status {response.status_code}")
            return response.status_code in [200, 202], f"Status SendGrid: {response.status_code}"
        except Exception as e:
            print(f"DEBUG: Erro ao enviar com SendGrid - {e}")
            return False, f"Ocorreu um erro ao enviar e-mail via SendGrid: {e}"

    elif provider == 'Gmail (SMTP)':
        try:
            # L√≥gica completa para o Gmail (adicionando o 'pass' para evitar o erro)
            pass
        except Exception as e:
            print(f"DEBUG: Erro ao enviar com Gmail - {e}")
            return False, f"Ocorreu um erro ao enviar e-mail via Gmail: {e}"

    return False, "Provedor de e-mail n√£o configurado ou inv√°lido."

# --- NOVAS FUN√á√ïES DE VALIDA√á√ÉO ---
def is_valid_url(url):
    """Verifica se uma string corresponde ao formato de um URL."""
    # Express√£o regular simples para validar URLs
    regex = re.compile(
        r'^(?:http|ftp)s?://' # http:// or https://
        r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\.)+(?:[A-Z]{2,6}\.?|[A-Z0-9-]{2,}\.?)|' # domain...
        r'localhost|' # localhost...
        r'\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})' # ...or ip
        r'(?::\d+)?' # optional port
        r'(?:/?|[/?]\S+)$', re.IGNORECASE)
    return re.match(regex, url) is not None

def is_valid_email(email):
    """Verifica se uma string corresponde ao formato de um e-mail."""
    # Express√£o regular para validar e-mails
    regex = re.compile(r'([A-Za-z0-9]+[.-_])*[A-Za-z0-9]+@[A-Za-z0-9-]+(\.[A-Z|a-z]{2,})+')
    return re.fullmatch(regex, email)

def load_and_process_project_data(jira_client, project_key):
    """
    Carrega, processa, enriquece e armazena em cache os dados de um projeto Jira.
    Esta vers√£o agora calcula e inclui o Cycle Time no DataFrame principal.
    """
    from jira_connector import get_project_issues, get_jira_fields
    from metrics_calculator import find_completion_date, filter_ignored_issues, calculate_cycle_time

    user_data = find_user(st.session_state['email'])
    project_config = get_project_config(project_key) or {}
    user_enabled_custom_fields = user_data.get('enabled_custom_fields', [])
    
    raw_issues_list = get_project_issues(jira_client, project_key, user_custom_fields=user_enabled_custom_fields)
    issues = filter_ignored_issues(raw_issues_list, project_config)
    
    if not issues:
        st.warning("Nenhuma issue foi encontrada para este projeto (ou todas foram ignoradas pela sua configura√ß√£o de status).")
        return pd.DataFrame(), []

    all_jira_fields = get_jira_fields(jira_client)
    field_id_to_name_map = {field['id']: field['name'] for field in all_jira_fields}

    processed_issues_data = []
    for issue in issues:
        fields_data = issue.raw['fields'].copy()
        fields_data['key'] = issue.key
        
        completion_date = find_completion_date(issue, project_config)
        fields_data['calculated_completion_date'] = completion_date
        
        # Calcula o Cycle Time se houver data de conclus√£o
        if completion_date:
            completion_datetime = pd.to_datetime(completion_date)
            fields_data['calculated_cycle_time'] = calculate_cycle_time(issue, completion_datetime, project_config)
        else:
            fields_data['calculated_cycle_time'] = None
            
        processed_issues_data.append(fields_data)

    df = pd.DataFrame(processed_issues_data)

    global_configs = st.session_state.get('global_configs', {})
    available_custom_fields = global_configs.get('custom_fields', [])
    enabled_field_name_to_type_map = {
        field['name']: field.get('type', 'Texto') 
        for field in available_custom_fields 
        if field['name'] in user_enabled_custom_fields
    }

    for col in df.columns:
        if col.startswith('customfield_'):
            field_name = field_id_to_name_map.get(col)
            if field_name and field_name in enabled_field_name_to_type_map:
                field_type = enabled_field_name_to_type_map[field_name]
                df[field_name] = df[col].apply(lambda x: x.get('value') if isinstance(x, dict) else x)
                if field_type == 'Num√©rico':
                    df[field_name] = pd.to_numeric(df[field_name], errors='coerce')
                elif field_type == 'Data':
                    df[field_name] = pd.to_datetime(df[field_name], errors='coerce').dt.date

    df.rename(columns={'summary': 'Issue', 'key': 'ID'}, inplace=True)
    df['Tipo de Issue'] = df['issuetype'].apply(lambda x: x['name'] if x else None)
    df['Status'] = df['status'].apply(lambda x: x['name'] if x else None)
    df['Respons√°vel'] = df['assignee'].apply(lambda x: x['displayName'] if x else 'N√£o atribu√≠do')
    df['Prioridade'] = df['priority'].apply(lambda x: x['name'] if x else None)
    df['Categoria de Status'] = df['status'].apply(lambda x: x['statusCategory']['name'] if x and 'statusCategory' in x else None)
    
    data_criacao_dt = pd.to_datetime(df['created']).dt.tz_localize(None)
    data_conclusao_dt = pd.to_datetime(df['calculated_completion_date'], errors='coerce').dt.tz_localize(None)

    df['Lead Time (dias)'] = (data_conclusao_dt - data_criacao_dt).dt.days
    df['Cycle Time (dias)'] = df['calculated_cycle_time'] # Adiciona a nova coluna
    
    df['Data de Cria√ß√£o'] = data_criacao_dt.dt.normalize()
    df['Data de Conclus√£o'] = data_conclusao_dt.dt.normalize()

    final_columns = ['ID', 'Issue', 'Tipo de Issue', 'Status', 'Respons√°vel', 'Prioridade', 'Categoria de Status', 'Data de Cria√ß√£o', 'Data de Conclus√£o', 'Lead Time (dias)', 'Cycle Time (dias)']
    
    final_columns.extend([name for name in enabled_field_name_to_type_map.keys() if name in df.columns])
    
    df_final = df[[col for col in final_columns if col in df.columns]].copy()

    return df_final, issues

def get_ai_product_vision(project_name, issues_data):
    """
    Usa a IA para analisar uma lista de issues e gerar uma vis√£o de produto,
    identificando gaps e sugerindo melhorias.
    """
    user_data = find_user(st.session_state['email'])
    provider = user_data.get('ai_provider_preference', 'Google Gemini')

    model_client = _get_ai_client_and_model(provider, user_data)
    if not model_client:
        return "An√°lise indispon√≠vel. Verifique a configura√ß√£o da sua chave de IA."

    # Prepara um resumo dos dados para enviar √† IA
    tasks_summary = "\n".join([f"- {item['Tipo']}: {item['T√≠tulo']} (Labels: {item['Labels']})" for item in issues_data])

    prompt = f"""
    Aja como um Diretor de Produto experiente. A sua tarefa √© analisar uma lista de tarefas (issues) do projeto "{project_name}" e gerar uma an√°lise estrat√©gica de produto em portugu√™s.

    **Dados das Tarefas Analisadas:**
    {tasks_summary}

    **A sua an√°lise deve seguir estritamente a seguinte estrutura em Markdown:**

    ### üîÆ Vis√£o Geral do Produto
    (Fa√ßa um resumo de 2-3 frases sobre o foco atual do produto, com base nos tipos de tarefas que est√£o a ser desenvolvidas.)

    ### üìä An√°lise da Natureza do Trabalho
    (Classifique o esfor√ßo da equipa. Estime, em percentagem, quanto do trabalho parece ser dedicado a: **Valor para o Usu√°rio** (novas features), **Manuten√ß√£o do Neg√≥cio** (bugs, d√©bitos t√©cnicos) e **Inova√ß√£o** (pesquisas, provas de conceito). Justifique a sua estimativa.)

    ### üîç Gaps e Oportunidades Identificados
    (Com base nas tarefas, identifique 2 a 3 "gaps" ou oportunidades que parecem estar a ser negligenciadas. Ex: "Parece haver pouco foco na experi√™ncia de novos utilizadores (onboarding)", ou "O grande n√∫mero de bugs no m√≥dulo de pagamentos sugere uma oportunidade de refatora√ß√£o para aumentar a estabilidade".)

    ### üöÄ Recomenda√ß√µes Estrat√©gicas
    (Sugira 2 a√ß√µes pr√°ticas e de alto impacto que a equipa de produto poderia tomar. As sugest√µes devem ser baseadas diretamente nos gaps que voc√™ identificou.)
    """

    try:
        if provider == "Google Gemini":
            response = model_client.generate_content(prompt)
            return response.text
        else: # OpenAI
            response = model_client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "Aja como um Diretor de Produto experiente."},
                    {"role": "user", "content": prompt}
                ]
            )
            return response.choices[0].message.content
    except Exception as e:
        return f"Ocorreu um erro ao gerar a an√°lise de produto: {e}"

def get_ai_strategic_diagnosis(project_name, client_name, issues_data, flow_metrics_summary, project_profile_summary, contextual_projects_summary=None):
    """
    Usa a IA para analisar o ecossistema de um projeto focado num cliente espec√≠fico,
    retornando um objeto JSON estruturado.
    """
    user_data = find_user(st.session_state['email'])
    provider = user_data.get('ai_provider_preference', 'Google Gemini')
    cleaned_response = "" # Inicializa para o bloco except

    model_client = _get_ai_client_and_model(provider, user_data)
    if not model_client:
        return {"error": "An√°lise indispon√≠vel. Verifique a configura√ß√£o da sua chave de IA."}

    tasks_summary_text = "\n".join([f"- {item['Tipo']}: {item['T√≠tulo']}" for item in issues_data[:20]])
    context_text = "\n".join([f"- {summary}" for summary in contextual_projects_summary]) if contextual_projects_summary else "Nenhum"

    prompt = f"""
    Aja como um Diretor de Contas de uma consultoria de TI. Sua tarefa √© analisar a sa√∫de da conta do cliente "{client_name}", associada ao projeto "{project_name}", e gerar um diagn√≥stico estrat√©gico em formato JSON.

    **DADOS PARA AN√ÅLISE:**
    1.  **Perfil da Conta (Dados do Cliente):**
        {project_profile_summary}
    2.  **M√©tricas Operacionais (Performance do Projeto):**
        {flow_metrics_summary}
    3.  **Contexto de Gest√£o (Tarefas relacionadas de outros projetos):**
        {context_text}
    4.  **Amostra de Tarefas Recentes:**
        {tasks_summary_text}

    **ESTRUTURA DA RESPOSTA (OBRIGAT√ìRIO):**
    Sua resposta DEVE ser um objeto JSON v√°lido, sem nenhuma outra palavra ou explica√ß√£o. Siga esta estrutura:
    {{
      "diagnostico_estrategico": "(Escreva aqui um resumo de 2-3 frases conectando os objetivos do cliente com a performance operacional do projeto.)",
      "analise_natureza_trabalho": "(Escreva aqui uma an√°lise sobre o tipo de trabalho que est√° a ser feito e se est√° alinhado com a estrat√©gia do cliente.)",
      "plano_de_acao_recomendado": [
        {{
          "acao": "(Escreva aqui a primeira a√ß√£o recomendada, clara e direta.)",
          "justificativa": "(Justifique a primeira a√ß√£o com base nos dados analisados.)"
        }},
        {{
          "acao": "(Escreva aqui a segunda a√ß√£o recomendada.)",
          "justificativa": "(Justifique a segunda a√ß√£o.)"
        }}
      ]
    }}
    """
    try:
        if provider == "Google Gemini":
            response = model_client.generate_content(prompt)
            cleaned_response = response.text.strip().replace("```json", "").replace("```", "")
        else: # OpenAI
            response = model_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": prompt}],
                response_format={"type": "json_object"}
            )
            cleaned_response = response.choices[0].message.content
        
        if not cleaned_response:
            return {"error": "A IA retornou uma resposta vazia."}

        return json.loads(cleaned_response)
    except Exception as e:
        return {"error": f"Ocorreu um erro ao processar a resposta da IA: {e}. Resposta recebida: '{cleaned_response}'"}

def get_ai_chat_response(initial_diagnosis, chat_history, user_question, issues_context):
    """
    Usa a IA para responder a uma pergunta de seguimento, com acesso √† lista de issues
    que originaram a an√°lise.
    """
    user_data = find_user(st.session_state['email'])
    provider = user_data.get('ai_provider_preference', 'Google Gemini')

    model_client = _get_ai_client_and_model(provider, user_data)
    if not model_client:
        return "N√£o consigo responder agora. Verifique a configura√ß√£o da sua chave de IA."

    # Prepara um resumo das issues para o contexto
    issues_summary = "\n".join([
        f"- Chave: {item['Key']}, T√≠tulo: {item['T√≠tulo']}, Status: {item['Status']}, Respons√°vel: {item['Respons√°vel']}"
        for item in issues_context
    ])

    history_for_prompt = "\n".join([f"- {msg['role']}: {msg['content']}" for msg in chat_history])

    prompt = f"""
    Aja como o mesmo Consultor de Produto que escreveu a an√°lise abaixo. A sua tarefa √© responder a uma pergunta de seguimento do utilizador.
    Voc√™ tem acesso √† lista completa de issues que foram usadas para gerar a an√°lise. Use esta lista para encontrar exemplos espec√≠ficos e dados concretos para justificar as suas respostas.

    **Diagn√≥stico Inicial (Contexto Principal):**
    {initial_diagnosis}

    **Dados das Issues (Use para pesquisar e encontrar exemplos):**
    {issues_summary}

    **Hist√≥rico da Conversa:**
    {history_for_prompt}

    **Nova Pergunta do Utilizador:**
    {user_question}

    Responda √† nova pergunta de forma concisa e direta, usando sempre o contexto e os dados das issues fornecidos. Se o utilizador pedir exemplos, cite as chaves das issues (ex: AMS-123).
    """

    try:
        if provider == "Google Gemini":
            response = model_client.generate_content(prompt)
            return response.text
        else: # OpenAI
            response = model_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": prompt}]
            )
            return response.choices[0].message.content
    except Exception as e:
        return f"Ocorreu um erro ao processar a sua pergunta: {e}"

def get_ai_user_story_from_figma(image_url, user_context, element_name):
    """
    Usa a IA para analisar uma imagem e gerar uma Job Story completa.
    Esta fun√ß√£o agora usa a configura√ß√£o de IA centralizada.
    """
    user_data = find_user(st.session_state['email'])
    provider = user_data.get('ai_provider_preference', 'Google Gemini')

    model_client = _get_ai_client_and_model(provider, user_data)

    if not model_client:
        return {"error": "An√°lise indispon√≠vel. Verifique a sua chave de API."}

    prompt = f"""
    Aja como um Product Owner e um Analista de QA experientes. A sua tarefa √© analisar a imagem de um elemento de interface chamado "{element_name}" e o contexto fornecido para criar uma Hist√≥ria de Usu√°rio completa em portugu√™s, no formato JSON.
    **Contexto Adicional:** {user_context}
    **Regras para a Gera√ß√£o:**
    1.  **T√≠tulo (title):** Crie um t√≠tulo curto e descritivo.
    2.  **Descri√ß√£o (description):** Escreva a hist√≥ria no formato "Job Story", usando asteriscos para negrito nos marcadores e quebras de linha, exatamente assim: "*Quando* <situa√ß√£o>\\n*Quero* <motiva√ß√£o>\\n*Ent√£o* <resultado>."
    3.  **Crit√©rios de Aceita√ß√£o (acceptance_criteria):** Crie uma lista de 3 a 5 crit√©rios de aceita√ß√£o claros, separados por uma nova linha (\\n).
    4.  **Cen√°rios de Teste BDD (bdd_scenarios):** Crie 2 a 3 cen√°rios de teste detalhados no formato BDD, usando asteriscos para negrito e quebras de linha, exatamente assim: "*Cen√°rio:* <nome do cen√°rio>\\n*Dado* <contexto>\\n*Quando* <a√ß√£o>\\n*Ent√£o* <resultado esperado>", com cada cen√°rio separado por duas novas linhas (\\n\\n).
    **Estrutura de Sa√≠da (Responda APENAS com o JSON):**
    {{"title": "...", "description": "...", "acceptance_criteria": "...", "bdd_scenarios": "..."}}
    """
    try:
        if provider == "Google Gemini":
            image_response = requests.get(image_url)
            image_parts = [{"mime_type": "image/png", "data": image_response.content}]
            prompt_parts = [prompt, image_parts[0]]
            response = model_client.generate_content(prompt_parts)
            cleaned_response = response.text.strip().replace("```json", "").replace("```", "")
        else: # OpenAI
            response = model_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": [{"type": "text", "text": prompt}, {"type": "image_url", "image_url": {"url": image_url}}] }],
                response_format={"type": "json_object"}
            )
            cleaned_response = response.choices[0].message.content
        return json.loads(cleaned_response)
    except Exception as e:
        return {"error": f"Ocorreu um erro ao gerar a hist√≥ria de usu√°rio: {e}"}

def get_ai_contract_analysis(pdf_bytes):
    """
    Usa a IA para analisar o texto de um contrato em PDF e extrair os campos-chave
    para uma Ordem de Servi√ßo, retornando um objeto JSON.
    """
    user_data = find_user(st.session_state['email'])
    provider = user_data.get('ai_provider_preference', 'Google Gemini')

    model_client = _get_ai_client_and_model(provider, user_data)
    if not model_client:
        return {"error": "An√°lise indispon√≠vel. Verifique a configura√ß√£o da sua chave de IA."}

    # Extrai o texto do PDF
    try:
        doc = fitz.open(stream=pdf_bytes, filetype="pdf")
        contract_text = ""
        for page in doc:
            contract_text += page.get_text()
        doc.close()
    except Exception as e:
        return {"error": f"N√£o foi poss√≠vel ler o ficheiro PDF: {e}"}

    prompt = f"""
    Aja como um Analista de Contratos s√™nior. A sua tarefa √© analisar o texto de uma Ordem de Servi√ßo (OS) ou contrato e extrair as seguintes informa√ß√µes, retornando o resultado num formato JSON.

    **Texto do Contrato para An√°lise:**
    {contract_text[:8000]} # Limita o tamanho do prompt

    **Regras para a Extra√ß√£o:**
    1.  **setor_demandante:** Identifique a √°rea ou setor que solicitou o servi√ßo.
    2.  **responsavel_demandante:** Identifique o nome do respons√°vel pela solicita√ß√£o.
    3.  **email_demandante:** Extraia o e-mail do respons√°vel.
    4.  **lider_projeto_gauge:** Identifique o nome do l√≠der de projeto do lado do fornecedor.
    5.  **data_emissao:** Encontre a data de emiss√£o do documento (formato DD/MM/AAAA).
    6.  **previsao_inicio:** Encontre a data de previs√£o de in√≠cio (formato DD/MM/AAAA).
    7.  **previsao_conclusao:** Encontre a data de previs√£o de t√©rmino (formato DD/MM/AAAA).
    8.  **justificativa_objetivo:** Fa√ßa um resumo conciso da justificativa e dos objetivos.
    9.  **escopo_tecnico:** Fa√ßa um resumo dos principais pontos do escopo t√©cnico ou dos entreg√°veis.
    10. **premissas:** Liste as premissas importantes.
    11. **orcamento:** Extraia o valor total do or√ßamento como um n√∫mero.
    12. **pagamento:** Resuma o cronograma ou as condi√ß√µes de pagamento.

    **Estrutura de Sa√≠da (Responda APENAS com o JSON. Se um campo n√£o for encontrado, retorne uma string vazia ""):**
    {{
        "setor_demandante": "", "responsavel_demandante": "", "email_demandante": "",
        "lider_projeto_gauge": "", "data_emissao": "", "previsao_inicio": "",
        "previsao_conclusao": "", "justificativa_objetivo": "", "escopo_tecnico": "",
        "premissas": "", "orcamento": 0.0, "pagamento": ""
    }}
    """

    try:
        if provider == "Google Gemini":
            response = model_client.generate_content(prompt)
            cleaned_response = response.text.strip().replace("```json", "").replace("```", "")
        else: # OpenAI
            response = model_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": prompt}],
                response_format={"type": "json_object"}
            )
            cleaned_response = response.choices[0].message.content

        return json.loads(cleaned_response)
    except Exception as e:
        return {"error": f"Ocorreu um erro ao analisar o contrato: {e}"}

def get_ai_os_from_context_and_contract(user_context, contract_text=None):
    """
    Usa a IA para analisar o contexto do utilizador e, opcionalmente, o texto de um contrato
    para preencher os campos de uma Ordem de Servi√ßo em formato JSON.
    """
    user_data = find_user(st.session_state['email'])
    provider = user_data.get('ai_provider_preference', 'Google Gemini')

    model_client = _get_ai_client_and_model(provider, user_data)
    if not model_client:
        return {"error": "An√°lise indispon√≠vel. Verifique a configura√ß√£o da sua chave de IA."}

    # --- PROMPT DIN√ÇMICO ---
    prompt_base = f"""
    Aja como um Gerente de Projetos s√™nior. A sua tarefa √© criar uma Ordem de Servi√ßo (OS) com base no contexto fornecido pelo utilizador e, se dispon√≠vel, complement√°-la com os detalhes encontrados no documento do contrato em anexo. Retorne o resultado num formato JSON.

    **Contexto da OS (Fonte Principal de Informa√ß√£o):**
    {user_context}
    """

    prompt_contrato = f"""
    **Texto do Contrato (Use para encontrar detalhes objetivos como nomes, datas, valores):**
    {contract_text[:8000]} # Limita o tamanho do prompt
    """ if contract_text else ""

    prompt_final = f"""
    {prompt_base}
    {prompt_contrato}

    **Regras para a Extra√ß√£o e Gera√ß√£o:**
    1.  Use o "Contexto da OS" como a principal fonte de verdade, especialmente para campos subjetivos como 'Justificativa & Objetivo' e 'Escopo T√©cnico'.
    2.  Use o "Texto do Contrato", se fornecido, para encontrar e extrair os valores para os outros campos.
    3.  Se um campo n√£o for encontrado em nenhuma das fontes, retorne uma string vazia "".

    **Estrutura de Sa√≠da (Responda APENAS com o JSON):**
    {{
        "setor_demandante": "", "responsavel_demandante": "", "email_demandante": "",
        "lider_projeto_gauge": "", "data_emissao": "DD/MM/AAAA", "previsao_inicio": "DD/MM/AAAA",
        "previsao_conclusao": "DD/MM/AAAA", "justificativa_objetivo": "", "escopo_tecnico": "",
        "premissas": "", "orcamento": "", "pagamento": ""
    }}
    """

    try:
        if provider == "Google Gemini":
            response = model_client.generate_content(prompt_final)
            cleaned_response = response.text.strip().replace("```json", "").replace("```", "")
        else: # OpenAI
            response = model_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": prompt_final}],
                response_format={"type": "json_object"}
            )
            cleaned_response = response.choices[0].message.content

        return json.loads(cleaned_response)
    except Exception as e:
        return {"error": f"Ocorreu um erro ao analisar o contrato: {e}"}

def get_ai_user_story_from_text(user_context):
    """
    Usa a IA para analisar o contexto do utilizador e gerar uma hist√≥ria de usu√°rio
    estruturada em JSON, no formato Job Story, incluindo cen√°rios BDD.
    """
    user_data = find_user(st.session_state['email'])
    provider = user_data.get('ai_provider_preference', 'Google Gemini')

    model_client = _get_ai_client_and_model(provider, user_data)
    if not model_client:
        return {"error": "An√°lise indispon√≠vel. Verifique a configura√ß√£o da sua chave de IA."}

    prompt = f"""
    Aja como um Product Owner e um Analista de QA experientes. A sua tarefa √© analisar o contexto fornecido para criar uma Hist√≥ria de Usu√°rio completa em portugu√™s, no formato JSON.
    **Contexto Fornecido pelo Utilizador:** {user_context}
    **Regras para a Gera√ß√£o:**
    1.  **T√≠tulo (title):** Crie um t√≠tulo curto e descritivo.
    2.  **Descri√ß√£o (description):** Escreva a hist√≥ria no formato "Job Story", usando asteriscos para negrito nos marcadores e quebras de linha, exatamente assim: "*Quando* <situa√ß√£o>\\n*Quero* <motiva√ß√£o>\\n*Ent√£o* <resultado>."
    3.  **Crit√©rios de Aceita√ß√£o (acceptance_criteria):** Crie uma lista de 3 a 5 crit√©rios de aceita√ß√£o claros, separados por uma nova linha (\\n).
    4.  **Cen√°rios de Teste BDD (bdd_scenarios):** Crie 2 a 3 cen√°rios de teste detalhados no formato BDD, usando asteriscos para negrito e quebras de linha, exatamente assim: "*Cen√°rio:* <nome do cen√°rio>\\n*Dado* <contexto>\\n*Quando* <a√ß√£o>\\n*Ent√£o* <resultado esperado>", com cada cen√°rio separado por duas novas linhas (\\n\\n).
    **Estrutura de Sa√≠da (Responda APENAS com o JSON):**
    {{"title": "...", "description": "...", "acceptance_criteria": "...", "bdd_scenarios": "..."}}
    """
    try:
        if provider == "Google Gemini":
            response = model_client.generate_content(prompt)
            cleaned_response = response.text.strip().replace("```json", "").replace("```", "")
        else: # OpenAI
            response = model_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": prompt}],
                response_format={"type": "json_object"}
            )
            cleaned_response = response.choices[0].message.content
        return json.loads(cleaned_response)
    except Exception as e:
        return {"error": f"Ocorreu um erro ao gerar a hist√≥ria de usu√°rio: {e}"}
def get_ai_os_from_jira_issue(issue_data_dict, layout_fields):
    """
    Usa a IA para analisar um dicion√°rio com todos os dados de uma issue do Jira
    e preencher os campos de uma Ordem de Servi√ßo em formato JSON.
    """
    user_data = find_user(st.session_state['email'])
    provider = user_data.get('ai_provider_preference', 'Google Gemini')
    raw_response_text = "" # Inicializa para o bloco except

    model_client = _get_ai_client_and_model(provider, user_data)
    if not model_client:
        return {"error": "An√°lise indispon√≠vel. Verifique a configura√ß√£o da sua chave de IA."}

    field_names = [field['field_name'] for field in layout_fields]
    json_structure_example = {field_name: "" for field_name in field_names}
    
    # Sanitiza os dados da issue para remover caracteres problem√°ticos
    sanitized_issue_dict = {}
    for key, value in issue_data_dict.items():
        if isinstance(value, str):
            sanitized_issue_dict[key] = value.encode('utf-8', 'ignore').decode('utf-8')
        else:
            sanitized_issue_dict[key] = value
    issue_context = "\n".join([f"- {key}: {value}" for key, value in sanitized_issue_dict.items() if value])

    prompt = f"""
    Sua √∫nica tarefa √© extrair dados de uma tarefa do Jira e preencher um formul√°rio JSON.

    **INFORMA√á√ïES DA TAREFA:**
    ```
    {issue_context}
    ```

    **FORMUL√ÅRIO JSON PARA PREENCHER:**
    {json.dumps(json_structure_example, indent=2, ensure_ascii=False)}

    **REGRAS:**
    1. As chaves no seu JSON de resposta devem ser EXATAMENTE IGUAIS √†s do formul√°rio.
    2. Preencha os valores com o m√°ximo de detalhes poss√≠vel com base nas informa√ß√µes da tarefa.
    3. Se uma informa√ß√£o n√£o for encontrada, retorne uma string vazia "" para o campo correspondente.
    4. Sua resposta final deve ser APENAS o c√≥digo JSON, sem nenhum outro texto, explica√ß√£o ou marcadores de c√≥digo.
    """

    try:
        if provider == "Google Gemini":
            response = model_client.generate_content(prompt)
            raw_response_text = response.text
        else: # OpenAI
            response = model_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": prompt}],
                response_format={"type": "json_object"}
            )
            raw_response_text = response.choices[0].message.content
        
        # 1. Remove marcadores de c√≥digo e espa√ßos em branco
        cleaned_text = raw_response_text.strip()
        if cleaned_text.startswith("```json"):
            cleaned_text = cleaned_text[7:]
        if cleaned_text.startswith("```"):
            cleaned_text = cleaned_text[3:]
        if cleaned_text.endswith("```"):
            cleaned_text = cleaned_text[:-3]
        
        cleaned_text = cleaned_text.strip()

        # 2. Tenta carregar o JSON
        if not cleaned_text:
             return {"error": "A IA retornou uma resposta vazia."}

        return json.loads(cleaned_text)
        
    except json.JSONDecodeError:
        # Erro se o texto n√£o for um JSON v√°lido
        return {"error": "A IA retornou um formato de dados inv√°lido (n√£o √© um JSON v√°lido).", "raw_response": raw_response_text}
    except Exception as e:
        # Captura outras exce√ß√µes (ex: falha na API)
        return {"error": f"Ocorreu um erro ao processar a resposta da IA: {e}", "raw_response": raw_response_text}

def get_ai_os_from_text(user_text, layout_fields):
    """
    Usa a IA para analisar um texto livre do usu√°rio e preencher os campos
    de uma Ordem de Servi√ßo em formato JSON, atuando como um analista t√©cnico.
    """
    user_data = find_user(st.session_state['email'])
    provider = user_data.get('ai_provider_preference', 'Google Gemini')
    raw_response_text = ""

    model_client = _get_ai_client_and_model(provider, user_data)
    if not model_client:
        return {"error": "An√°lise indispon√≠vel. Verifique a configura√ß√£o da sua chave de IA."}

    field_names = [
        field['field_name'] for field in layout_fields 
        if field.get('field_type') not in ["Subt√≠tulo", "Valor Calculado", "Imagem"]
    ]
    json_structure_example = {field_name: "" for field_name in field_names}

    # --- PROMPT APRIMORADO COM PERSONA E EXEMPLO T√âCNICO ---
    prompt = f"""
    **PERSONA:** Voc√™ √© a Gauge AI, uma assistente especialista em engenharia de software e gest√£o de projetos. Sua tarefa √© atuar como um analista de neg√≥cios s√™nior, transformando uma descri√ß√£o simples de uma necessidade em um texto t√©cnico, detalhado –∏ bem estruturado, adequado para uma Ordem de Servi√ßo (OS). Voc√™ deve inferir detalhes t√©cnicos, detalhar o escopo e enriquecer a descri√ß√£o inicial.

    **EXEMPLO DE TAREFA:**
    * **Texto do Usu√°rio:** "Preciso criar uma nova tela de login para o app mobile. O design j√° foi aprovado e o prazo de entrega √© para a pr√≥xima sexta-feira."
    * **Formul√°rio para Preencher:**
        {{
            "T√≠tulo da Demanda": "",
            "Objetivo": "",
            "Escopo Detalhado": "",
            "Prazo Estimado": ""
        }}
    * **Sua Resposta JSON (Exemplo de alta qualidade):**
        {{
            "T√≠tulo da Demanda": "Desenvolvimento da Nova Interface de Autentica√ß√£o para Aplicativo M√≥vel",
            "Objetivo": "Implementar uma nova interface de usu√°rio (UI) para o processo de login e autentica√ß√£o no aplicativo m√≥vel, visando melhorar a experi√™ncia do usu√°rio (UX), refor√ßar a seguran√ßa com valida√ß√£o de campos em tempo real e garantir a compatibilidade com os sistemas de backend existentes.",
            "Escopo Detalhado": "O escopo compreende o desenvolvimento front-end dos seguintes componentes: campo de e-mail com valida√ß√£o de formato, campo de senha com op√ß√£o de visualiza√ß√£o, bot√£o de 'Entrar' com feedback de estado (loading, erro), link para recupera√ß√£o de senha e integra√ß√£o com a API de autentica√ß√£o. Dever√° ser assegurada a responsividade para diferentes tamanhos de tela e a implementa√ß√£o de tratamento de erros para cen√°rios como credenciais inv√°lidas ou falhas de conex√£o.",
            "Prazo Estimado": "Pr√≥xima sexta-feira"
        }}
    ---
    **TAREFA REAL:**

    **Texto Fornecido Pelo Usu√°rio:**
    ```
    {user_text}
    ```

    **Formul√°rio JSON para Preencher (Sua Resposta):**
    {json.dumps(json_structure_example, indent=2, ensure_ascii=False)}

    **REGRAS FINAIS:**
    1.  Analise o texto do usu√°rio e preencha o formul√°rio JSON, enriquecendo-o com detalhes t√©cnicos e linguagem profissional.
    2.  As chaves no seu JSON devem ser **EXATAMENTE IGUAIS** √†s do formul√°rio.
    3.  Seja o mais **DETALHADO** poss√≠vel. Infira requisitos t√©cnicos comuns quando apropriado.
    4.  Responda **APENAS** com o c√≥digo JSON final, sem nenhum outro texto ou explica√ß√£o.
    """

    try:
        if provider == "Google Gemini":
            response = model_client.generate_content(prompt)
            raw_response_text = response.text
        else: # OpenAI
            response = model_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": prompt}],
                response_format={"type": "json_object"}
            )
            raw_response_text = response.choices[0].message.content
        
        cleaned_text = raw_response_text.strip()
        if cleaned_text.startswith("```json"):
            cleaned_text = cleaned_text[7:]
        if cleaned_text.startswith("```"):
            cleaned_text = cleaned_text[3:]
        if cleaned_text.endswith("```"):
            cleaned_text = cleaned_text[:-3]
        
        cleaned_text = cleaned_text.strip()

        if not cleaned_text:
             return {"error": "A IA retornou uma resposta vazia."}

        return json.loads(cleaned_text)
        
    except json.JSONDecodeError:
        return {"error": "A IA retornou um formato de dados inv√°lido (n√£o √© um JSON v√°lido).", "raw_response": raw_response_text}
    except Exception as e:
        return {"error": f"Ocorreu um erro ao processar a resposta da IA: {e}", "raw_response": raw_response_text}
    
def load_local_css(file_path):
    """L√™ um arquivo CSS e o injeta na aplica√ß√£o Streamlit."""
    try:
        with open(file_path) as f:
            st.markdown(f"<style>{f.read()}</style>", unsafe_allow_html=True)
    except FileNotFoundError:
        st.error(f"Arquivo CSS n√£o encontrado: {file_path}")

def get_ai_team_performance_analysis(team_performance_df):
    """
    Usa a IA para analisar um DataFrame de compet√™ncias da equipa (incluindo coment√°rios)
    e gerar uma an√°lise de performance detalhada.
    """
    user_data = find_user(st.session_state['email'])
    provider = user_data.get('ai_provider_preference', 'Google Gemini')

    model_client = _get_ai_client_and_model(provider, user_data)
    if not model_client:
        return "### üîÆ An√°lise Indispon√≠vel\nPara usar esta funcionalidade, por favor, configure a sua chave de API."

    # Remove colunas com coment√°rios vazios para um prompt mais limpo
    df_clean = team_performance_df.dropna(axis=1, how='all')
    dados_csv = df_clean.to_csv(index=False)
    
    prompt = f"""
    Aja como um Diretor de RH (People & Culture Director) especialista em an√°lise de performance. A sua tarefa √© analisar os dados de uma matriz de compet√™ncias que inclui tanto a avalia√ß√£o quantitativa (n√≠veis) quanto a qualitativa (coment√°rios), e fornecer uma an√°lise estrat√©gica profunda em Portugu√™s.

    **Dados da Matriz de Compet√™ncias (formato CSV):**
    (N√≠veis de 0 a 5; Coment√°rios do Plano de Desenvolvimento Individual - PDI)
    ```csv
    {dados_csv}
    ```

    **Estrutura da An√°lise (Obrigat√≥rio):**
    A sua resposta DEVE ser formatada em Markdown, ser perspicaz e usar tanto os n√≠veis quanto os coment√°rios para justificar as suas conclus√µes. Siga estritamente esta estrutura:

    ### üìà Resumo Executivo
    * Forne√ßa um par√°grafo com uma vis√£o geral do perfil da equipa. Conecte os n√≠veis de compet√™ncia com os temas recorrentes nos coment√°rios. (Ex: "A equipa demonstra alta profici√™ncia t√©cnica em [Compet√™ncia X], mas os coment√°rios, tanto dos l√≠deres quanto dos pr√≥prios membros, apontam para uma necessidade de desenvolver a comunica√ß√£o com stakeholders.")

    ### ‚úÖ Pontos Fortes e Sinergias
    * Identifique os pontos fortes com base nos n√≠veis altos. **Use os coment√°rios para dar profundidade.** (Ex: "A profici√™ncia em 'Metodologias √Ågeis' √© evidente, e o coment√°rio do l√≠der para [Membro Y] sobre 'propor melhorias no processo de sprint' confirma esta senioridade.")
    * Aponte sinergias ou discrep√¢ncias positivas entre a autoavalia√ß√£o e a avalia√ß√£o do l√≠der.

    ### üéØ Oportunidades Estrat√©gicas de Desenvolvimento
    * Aponte as compet√™ncias com n√≠veis mais baixos. **Use os coment√°rios para identificar a causa-raiz.** (Ex: "A baixa avalia√ß√£o em 'Gest√£o de Stakeholders' √© corroborada por v√°rios PDIs que mencionam 'melhorar a clareza nas apresenta√ß√µes' e 'antecipar as necessidades do cliente'.")
    * Identifique temas comuns nos PDIs que representem uma oportunidade de treino em grupo.

    ### ü§ù Plano de A√ß√£o e Mentoria
    * Com base em toda a an√°lise (n√≠veis e coment√°rios), sugira um plano de a√ß√£o pr√°tico.
    * Sugira mentorias internas, justificando a escolha com base nos dados. (Ex: "O(A) **[Nome do Mentor(a)]** √© um(a) especialista em **[Compet√™ncia Z]** e o seu PDI demonstra interesse em lideran√ßa. Ele(a) poderia mentorar o(a) **[Nome do Mentorado(a)]**, cujo PDI expressa a necessidade de 'ganhar autonomia' nesta √°rea.")
    """

    try:
        if provider == "Google Gemini":
            response = model_client.generate_content(prompt)
            return response.text
        else: # OpenAI
            response = model_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": prompt}]
            )
            return response.choices[0].message.content
    except Exception as e:
        st.error(f"Ocorreu um erro ao comunicar com a IA: {e}")
        return "Ocorreu uma falha ao tentar gerar a an√°lise. Por favor, tente novamente."
    
def calculate_kpi_value(op, field, df):
    """
    Calcula um valor de KPI (Soma, M√©dia, Contagem) a partir de um DataFrame.
    Esta fun√ß√£o reside em utils.py para evitar importa√ß√µes circulares.
    """
    if op == 'Contagem':
        return len(df)
    
    if not field or field == "Contagem de Issues":
        return len(df)

    if field not in df.columns:
        st.warning(f"O campo '{field}' usado no KPI n√£o foi encontrado nos dados atuais.")
        return 0 

    numeric_series = pd.to_numeric(df[field], errors='coerce').dropna()
    
    if numeric_series.empty:
        return 0

    if op == 'Soma':
        return numeric_series.sum()
    if op == 'M√©dia':
        return numeric_series.mean()
    
    return 0

def save_help_topic(topic_key, content):
    """Guarda o conte√∫do de um t√≥pico de ajuda num ficheiro JSON."""
    file_path = Path(__file__).parent / "help_documentation.json"
    docs = {}
    if file_path.exists():
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                docs = json.load(f)
        except (json.JSONDecodeError, UnicodeDecodeError):
            pass # Se o ficheiro estiver corrompido, ser√° sobrescrito
    
    docs[topic_key] = {
        "content": content,
        "last_updated": datetime.now().isoformat()
    }
    
    with open(file_path, 'w', encoding='utf-8') as f:
        json.dump(docs, f, indent=4, ensure_ascii=False)

def load_help_topics():
    """Carrega todos os t√≥picos de ajuda do ficheiro JSON."""
    file_path = Path(__file__).parent / "help_documentation.json"
    if file_path.exists():
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except (json.JSONDecodeError, UnicodeDecodeError):
            return {}
    return {}

def get_ai_page_summary_and_faq(page_name, page_content):
    """
    Usa a IA para analisar o c√≥digo de uma P√ÅGINA ESPEC√çFICA e gerar
    uma p√°gina de "Sobre" e um FAQ t√©cnico para ela.
    """
    user_data = find_user(st.session_state['email'])
    provider = user_data.get('ai_provider_preference', 'Google Gemini')

    model_client = _get_ai_client_and_model(provider, user_data)
    if not model_client:
        return "### An√°lise Indispon√≠vel\nPara usar esta funcionalidade, configure a sua chave de API."

    prompt = f"""
    Aja como um Redator T√©cnico (Technical Writer). A sua tarefa √© analisar o c√≥digo-fonte de uma p√°gina espec√≠fica de uma aplica√ß√£o Streamlit chamada "{page_name}" e gerar uma documenta√ß√£o clara em Portugu√™s.

    **C√≥digo da P√°gina "{page_name}":**
    ```python
    {page_content}
    ```

    **Estrutura da Resposta (Obrigat√≥rio):**
    A sua resposta DEVE ser formatada em Markdown e seguir estritamente esta estrutura:

    ### Sobre a P√°gina: {page_name}
    (Escreva um par√°grafo conciso sobre o prop√≥sito principal e a funcionalidade desta p√°gina espec√≠fica, com base no c√≥digo fornecido.)

    ### Como Usar
    (Crie um passo a passo ou uma lista de t√≥picos explicando como um utilizador deve interagir com as principais funcionalidades da p√°gina.)

    ### Perguntas Frequentes (FAQ) da P√°gina
    **(Crie de 3 a 5 perguntas e respostas focadas exclusivamente nesta p√°gina. As perguntas devem ser do tipo 'Como eu fa√ßo para...' ou 'O que significa...').**

    **P: [Pergunta relevante para a p√°gina]**
    *R: [Resposta clara e direta baseada no c√≥digo da p√°gina.]*

    **P: [Outra pergunta relevante]**
    *R: [Outra resposta clara.]*
    """

    try:
        if provider == "Google Gemini":
            response = model_client.generate_content(prompt)
            return response.text
        else: # OpenAI
            response = model_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": prompt}]
            )
            return response.choices[0].message.content
    except Exception as e:
        st.error(f"Ocorreu um erro ao comunicar com a IA: {e}")
        return "Ocorreu uma falha ao tentar gerar a an√°lise. Por favor, tente novamente."
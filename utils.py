# utils.py

import streamlit as st
import json, os, pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from fpdf import FPDF
import pandas as pd
import uuid
import base64
import google.generativeai as genai
from security import find_user, decrypt_token
from datetime import datetime, timedelta
import openai
from sklearn.linear_model import LinearRegression
import numpy as np
import smtplib
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText
from email.mime.application import MIMEApplication
from pathlib import Path
import re
from jira_connector import *
from security import *
from metrics_calculator import *
import fitz
import sendgrid 
from sendgrid.helpers.mail import Mail, Attachment, FileContent, FileName, FileType, Disposition
import io

def load_config(file_path, default_value):
    if os.path.exists(file_path):
        with open(file_path, 'r', encoding='utf-8') as f:
            try: return json.load(f)
            except (json.JSONDecodeError, UnicodeDecodeError): return default_value
    return default_value

def save_config(data, file_path):
    with open(file_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, indent=4)

def convert_dates_in_filters(filters):
    """
    Percorre uma lista de filtros e converte quaisquer objetos de data
    para strings no formato ISO (YYYY-MM-DD) para serem compat√≠veis com o MongoDB.
    """
    if not filters:
        return []
    
    sanitized_filters = []
    for f in filters:
        new_filter = f.copy()
        # Verifica se 'values' √© uma tupla/lista (t√≠pico de filtros de data)
        if 'values' in new_filter and isinstance(new_filter['values'], (list, tuple)):
            try:
                # Converte cada item se for um objeto de data
                new_filter['values'] = [
                    v.isoformat() if hasattr(v, 'isoformat') else v 
                    for v in new_filter['values']
                ]
            except Exception:
                # Se a convers√£o falhar, mant√©m os valores originais
                pass
        sanitized_filters.append(new_filter)
    return sanitized_filters

def render_chart(chart_config, df, return_fig=False):
    """
    Renderiza um √∫nico gr√°fico, aplicando os seus pr√≥prios filtros ao dataframe original.
    Esta √© a vers√£o final e completa.
    """
    try:
        df_to_render = df.copy() 
        
        # --- L√ìGICA DE FILTRAGEM COMPLETA E CORRIGIDA ---
        chart_filters = chart_config.get('filters', [])
        if chart_filters:
            for f in chart_filters:
                field, op, val = f.get('field'), f.get('operator'), f.get('value')
                if field and op and val is not None and field in df_to_render.columns:
                    try:
                        # Filtros Categ√≥ricos e Num√©ricos
                        if op == '√© igual a': df_to_render = df_to_render[df_to_render[field] == val]
                        elif op == 'n√£o √© igual a': df_to_render = df_to_render[df_to_render[field] != val]
                        elif op == 'est√° em': df_to_render = df_to_render[df_to_render[field].isin(val)]
                        elif op == 'n√£o est√° em': df_to_render = df_to_render[~df_to_render[field].isin(val)]
                        elif op == 'maior que': df_to_render = df_to_render[pd.to_numeric(df_to_render[field], errors='coerce') > val]
                        elif op == 'menor que': df_to_render = df_to_render[pd.to_numeric(df_to_render[field], errors='coerce') < val]
                        elif op == 'entre' and isinstance(val, list) and len(val) == 2:
                             df_to_render = df_to_render[pd.to_numeric(df_to_render[field], errors='coerce').between(val[0], val[1])]
                        
                        # Filtros de Data
                        elif op == "Per√≠odos Relativos":
                            days_map = {
                                "√öltimos 7 dias": 7, "√öltimos 14 dias": 14, "√öltimos 30 dias": 30, 
                                "√öltimos 60 dias": 60, "√öltimos 90 dias": 90, "√öltimos 120 dias": 120, 
                                "√öltimos 150 dias": 150, "√öltimos 180 dias": 180
                            }
                            end_date = pd.to_datetime(datetime.now().date())
                            start_date = end_date - timedelta(days=days_map.get(val, 0))
                            df_to_render = df_to_render[(pd.to_datetime(df_to_render[field]) >= start_date) & (pd.to_datetime(df_to_render[field]) <= end_date)]
                        elif op == "Per√≠odo Personalizado" and len(val) == 2:
                            start_date, end_date = pd.to_datetime(val[0]), pd.to_datetime(val[1])
                            df_to_render = df_to_render[(pd.to_datetime(df_to_render[field]) >= start_date) & (pd.to_datetime(df_to_render[field]) <= end_date)]
                    except Exception:
                        pass # Ignora filtros malformados
        
        # --- ETAPA 2: VALIDA√á√ÉO DE CAMPOS ---
        required_cols = []
        chart_type = chart_config.get('type')
        if chart_type in ['dispers√£o', 'linha']:
            required_cols.extend([chart_config.get('x'), chart_config.get('y')])
            if chart_config.get('color_by') and chart_config.get('color_by') != 'Nenhum': required_cols.append(chart_config.get('color_by'))
        elif chart_type in ['barra', 'linha_agregada', 'pizza', 'treemap', 'funil']:
            required_cols.append(chart_config.get('dimension'))
            if chart_config.get('measure') != 'Contagem de Issues': required_cols.append(chart_config.get('measure'))
        elif chart_type == 'tabela':
            required_cols.extend(chart_config.get('columns', []))
        elif chart_type == 'pivot_table':
            required_cols.extend([chart_config.get('rows'), chart_config.get('columns'), chart_config.get('values')])
        
        missing_cols = [col for col in required_cols if col and col not in df_to_render.columns]
        if missing_cols:
            if not return_fig:
                st.warning(f"N√£o foi poss√≠vel renderizar esta visualiza√ß√£o.", icon="‚ö†Ô∏è")
                st.error(f"Motivo: O(s) campo(s) **{', '.join(missing_cols)}** n√£o foi/foram encontrado(s) nos dados atuais.")
                st.badge("Habilite o campo que deseja utilizar e **atualize os dados**", color='orange')
            return None

        # --- ETAPA 3: RENDERIZA√á√ÉO ---
        source_type = chart_config.get('source_type', 'visual')
        fig = None
        template = "plotly_white"

        if chart_type == 'indicator':
            # Gr√°ficos do tipo 'indicator' (st.metric) n√£o s√£o export√°veis como imagem
            if return_fig:
                return None
                
            if source_type == 'jql':
                with st.spinner("A calcular KPI com JQL..."):
                    val_a = get_jql_issue_count(st.session_state.jira_client, chart_config.get('jql_a'))
                    final_value = float(val_a)
                    if chart_config.get('jql_b') and chart_config.get('jql_operation'):
                        val_b = get_jql_issue_count(st.session_state.jira_client, chart_config.get('jql_b'))
                        op = chart_config.get('jql_operation')
                        if op == 'Dividir (A / B)': final_value = (val_a / val_b) * 100 if val_b > 0 else 0
                        elif op == 'Somar (A + B)': final_value = val_a + val_b
                        elif op == 'Subtrair (A - B)': final_value = val_a - val_b
                        elif op == 'Multiplicar (A * B)': final_value = val_a * val_b
                    
                    value_str = f"{int(final_value):,}" if final_value == int(final_value) else f"{final_value:,.2f}"
                    if chart_config.get('jql_operation') == 'Dividir (A / B)': value_str += "%"
                    delta_value = None
                    if chart_config.get('jql_baseline'):
                        baseline_value = get_jql_issue_count(st.session_state.jira_client, chart_config.get('jql_baseline'))
                        delta_value = final_value - baseline_value
                    delta_str = None
                    if delta_value is not None:
                        delta_str = f"{int(delta_value):,}" if delta_value == int(delta_value) else f"{delta_value:,.2f}"
                    st.metric(label=chart_config.get('title', 'JQL KPI'), value=value_str, delta=delta_str, label_visibility="collapsed")
                return
            
            else: # Construtor Visual
                def calculate_value(op, field, data_frame):
                    if not op or not field: return None
                    if field == 'Contagem de Issues': return len(data_frame)
                    if field not in data_frame.columns: return None
                    if op == 'Contagem': return len(data_frame.dropna(subset=[field]))
                    numeric_series = pd.to_numeric(data_frame[field], errors='coerce')
                    if numeric_series.isnull().all(): return None
                    if op == 'Soma': return numeric_series.sum()
                    if op == 'M√©dia': return numeric_series.mean()
                    return None
                
                num_value = calculate_value(chart_config['num_op'], chart_config['num_field'], df_to_render)
                final_value = num_value
                if chart_config.get('use_den'):
                    den_value = calculate_value(chart_config['den_op'], chart_config['den_field'], df_to_render)
                    if den_value is not None and den_value != 0 and num_value is not None:
                        final_value = (num_value / den_value)
                    else: final_value = None
                
                if final_value is None or pd.isna(final_value):
                    st.metric(label=chart_config.get('title', 'KPI'), value="N/A", label_visibility="collapsed")
                    return
                
                style = chart_config.get('style', 'N√∫mero Grande')
                if style == 'N√∫mero Grande':
                    delta_value, mean_val = None, 0
                    if chart_config.get('show_delta') and chart_config.get('num_field') != 'Contagem de Issues':
                        mean_val = calculate_value('M√©dia', chart_config['num_field'], df_to_render)
                        if mean_val is not None and pd.notna(mean_val) and mean_val > 0: delta_value = final_value - mean_val
                    value_str = f"{int(final_value):,}" if pd.notna(final_value) and final_value == int(final_value) else f"{final_value:,.2f}"
                    delta_str = None
                    if delta_value is not None:
                        delta_str = f"{int(delta_value):,}" if delta_value == int(delta_value) else f"{delta_value:,.2f}"
                    st.metric(label=chart_config.get('title', 'KPI'), value=value_str, delta=delta_str, help=f"Varia√ß√£o vs. m√©dia ({mean_val:,.2f})" if delta_value is not None else None, label_visibility="collapsed")
                elif style in ['Medidor (Gauge)', 'Gr√°fico de Bala (Bullet)']:
                    target_value = 100
                    if chart_config.get('target_type') == 'Valor Fixo': target_value = chart_config.get('gauge_max_static', 100)
                    else:
                        if chart_config.get('target_op') and chart_config.get('target_field'): target_value = calculate_value(chart_config['target_op'], chart_config['target_field'], df_to_render)
                    poor_limit = chart_config.get('gauge_poor_threshold', target_value * 0.5); good_limit = chart_config.get('gauge_good_threshold', target_value * 0.8); fig = go.Figure()
                    if style == 'Medidor (Gauge)':
                        fig.add_trace(go.Indicator(mode = "gauge+number", value = final_value, gauge = {'axis': {'range': [chart_config.get('gauge_min', 0), target_value]}, 'bar': {'color': chart_config.get('gauge_bar_color', '#1f77b4')}, 'steps': [{'range': [0, poor_limit], 'color': 'rgba(255, 0, 0, 0.15)'}, {'range': [poor_limit, good_limit], 'color': 'rgba(255, 255, 0, 0.25)'}, {'range': [good_limit, target_value], 'color': 'rgba(0, 255, 0, 0.25)'}], 'threshold': {'line': {'color': chart_config.get('gauge_target_color', '#d62728'), 'width': 4}, 'thickness': 0.9, 'value': target_value}}))
                        fig.update_layout(height=150, margin=dict(l=20,r=20,t=1,b=1))
                    elif style == 'Gr√°fico de Bala (Bullet)':
                        fig.add_trace(go.Indicator(mode = "number+gauge", value = final_value, gauge = {'shape': "bullet", 'axis': {'range': [None, target_value]}, 'threshold': {'line': {'color': chart_config.get('gauge_target_color', '#d62728'), 'width': 3}, 'thickness': 0.9, 'value': target_value}, 'steps': [{'range': [0, poor_limit], 'color': "rgba(255, 0, 0, 0.25)"}, {'range': [poor_limit, good_limit], 'color': "rgba(255, 255, 0, 0.35)"}, {'range': [good_limit, target_value], 'color': "rgba(0, 255, 0, 0.35)"}], 'bar': {'color': chart_config.get('gauge_bar_color', '#1f77b4'), 'thickness': 0.5}}))
                        fig.update_layout(height=100, margin=dict(l=1,r=1,t=20,b=20))

        elif chart_type in ['dispers√£o', 'linha']:
            x_col, y_col, color_col = chart_config['x'], chart_config['y'], chart_config.get('color_by')
            plot_df = df_to_render.dropna(subset=[x_col, y_col]).copy()
            color_param = color_col if color_col and color_col != "Nenhum" and color_col in plot_df.columns else None
            text_param = y_col if chart_config.get('show_data_labels') else None

            if chart_type == 'dispers√£o':
                fig = px.scatter(plot_df, x=x_col, y=y_col, color=color_param, title=None, hover_name="Issue", template=template, text=text_param)
            else: # linha
                plot_df.sort_values(by=x_col, inplace=True)
                fig = px.line(plot_df, x=x_col, y=y_col, color=color_param, title=None, hover_name="Issue", template=template, markers=True, text=text_param)
            
            if chart_config.get('show_data_labels') and fig:
                fig.update_traces(textposition='top center', texttemplate='%{text:,.2f}')
 
        elif chart_type in ['barra', 'linha_agregada', 'pizza', 'treemap', 'funil']:
            measure, dimension, agg = chart_config['measure'], chart_config['dimension'], chart_config.get('agg')
            
            if measure == 'Contagem de Issues':
                grouped_df = df_to_render.groupby(dimension).size().reset_index(name='Contagem'); y_axis, values_col = 'Contagem', 'Contagem'
            elif agg == 'Contagem Distinta':
                new_column_name = f"Contagem de {measure}"; grouped_df = df_to_render.groupby(dimension)[measure].nunique().reset_index(name=new_column_name); y_axis, values_col = new_column_name, new_column_name
            else:
                agg_func = 'sum' if agg == 'Soma' else 'mean'; df_to_render[measure] = pd.to_numeric(df_to_render[measure], errors='coerce'); grouped_df = df_to_render.groupby(dimension)[measure].agg(agg_func).reset_index(); y_axis, values_col = measure, measure
            
            show_labels = chart_config.get('show_data_labels', False)
            text_param = y_axis if show_labels else None

            if chart_type == 'barra': fig = px.bar(grouped_df, x=dimension, y=y_axis, color=dimension, title=None, template=template, text=text_param)
            elif chart_type == 'linha_agregada': fig = px.line(grouped_df.sort_values(by=dimension), x=dimension, y=y_axis, title=None, template=template, markers=True, text=text_param)
            elif chart_type == 'pizza': fig = px.pie(grouped_df, names=dimension, values=values_col, title=None, template=template)
            elif chart_type == 'treemap': fig = px.treemap(grouped_df, path=[px.Constant("Todos"), dimension], values=values_col, color=y_axis, title=None, color_continuous_scale='Blues', template=template)
            elif chart_type == 'funil': fig = px.funnel(grouped_df, x=y_axis, y=dimension, title=None, template=template, text=text_param)
            
            if show_labels and fig:
                if chart_type in ['barra', 'linha_agregada', 'funil']:
                    is_float = pd.api.types.is_float_dtype(grouped_df[y_axis])
                    text_template = '%{text:,.2f}' if is_float else '%{text:,.0f}'
                    fig.update_traces(texttemplate=text_template, textposition='outside')
                elif chart_type == 'pizza':
                    fig.update_traces(textinfo='percent+label', textposition='inside')
                elif chart_type == 'treemap':
                    fig.update_traces(textinfo='label+value+percent root')
        
        if return_fig:
            return fig
        elif fig is not None:
            st.plotly_chart(fig, use_container_width=True)
            
    except Exception as e:
        if not return_fig:
            st.error(f"Erro ao gerar a visualiza√ß√£o '{chart_config.get('title', 'Desconhecido')}': {e}")
        return None

# ===== CLASSE DE PDF E FUN√á√ïES DE GERA√á√ÉO DE DOCUMENTOS =====
class PDF(FPDF):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.os_title = "" 

    def header(self):
        try:
            self.image('images/gauge-logo.svg', 10, 8, 33)
        except Exception as e:
            print(f"N√£o foi poss√≠vel carregar o logo: {e}")
        
        self.set_y(13)
        self.set_x(45)
        self.set_font('Roboto', 'B', 16)
        
        remaining_width = self.w - 45 - self.r_margin
        self.cell(remaining_width, 10, self.os_title, 0, 0, 'C')
        
        self.ln(20)

    def footer(self):
        self.set_y(-15)
        self.set_font('Roboto', 'I', 8)
        self.set_text_color(128, 128, 128)
        self.cell(0, 10, 'Documento Gerado pelo Gauge Product Hub', 0, 0, 'L')
        self.cell(0, 10, f'P√°gina {self.page_no()}', 0, 0, 'R')

def clean_text(text):
    if text is None: return ""
    return str(text)

def create_os_pdf(os_data):
    pdf = PDF()
    pdf.os_title = f"Ordem de Servi√ßo: {clean_text(os_data.get('layout_name', 'N/A'))}"

    base_dir = Path(__file__).resolve().parent
    font_dir = base_dir / "fonts"
    roboto_regular_path = font_dir / "Roboto-Regular.ttf"
    roboto_bold_path = font_dir / "Roboto-Bold.ttf"
    roboto_italic_path = font_dir / "Roboto-Italic.ttf"

    if not roboto_regular_path.is_file(): raise FileNotFoundError(f"Arquivo de fonte n√£o encontrado: {roboto_regular_path}")
    if not roboto_bold_path.is_file(): raise FileNotFoundError(f"Arquivo de fonte n√£o encontrado: {roboto_bold_path}")
    if not roboto_italic_path.is_file(): raise FileNotFoundError(f"Arquivo de fonte n√£o encontrado: {roboto_italic_path}")

    pdf.add_font('Roboto', '', str(roboto_regular_path))
    pdf.add_font('Roboto', 'B', str(roboto_bold_path))
    pdf.add_font('Roboto', 'I', str(roboto_italic_path))
    
    pdf.add_page()
    
    pdf.set_font('Roboto', 'B', 12)
    pdf.cell(0, 10, 'Detalhes da Ordem de Servi√ßo', 0, 1, 'L')
    pdf.ln(2)

    for field_data in os_data.get('custom_fields_layout', []):
        field_name = field_data.get('field_name')
        field_type = field_data.get('field_type')
        value = os_data.get('custom_fields', {}).get(field_name)

        if value is None or value == '' or (isinstance(value, list) and not value) or (isinstance(value, pd.DataFrame) and value.empty):
            continue

        pdf.set_font('Roboto', 'B', 11)
        pdf.multi_cell(0, 8, clean_text(f"{field_name}:"), border=0, align='L', ln=1)
        pdf.set_font('Roboto', '', 11)

        if field_type == "Tabela":
            if isinstance(value, list) and value:
                df_table = pd.DataFrame(value)
                if not df_table.empty:
                    pdf.ln(2)
                    pdf.set_font('Roboto', 'B', 10)
                    num_cols = len(df_table.columns)
                    col_width = 190 / num_cols if num_cols > 0 else 190
                    for col in df_table.columns:
                        pdf.cell(col_width, 7, clean_text(str(col)), 1, 0, 'C')
                    pdf.ln()
                    
                    pdf.set_font('Roboto', '', 10)
                    for index, row in df_table.iterrows():
                        y_before_row = pdf.get_y(); x_before_row = pdf.get_x(); max_y = y_before_row
                        for i, col in enumerate(df_table.columns):
                            pdf.set_xy(x_before_row + (i * col_width), y_before_row)
                            pdf.multi_cell(col_width, 7, clean_text(str(row[col])), 1, 'L')
                            if pdf.get_y() > max_y: max_y = pdf.get_y()
                        pdf.set_y(max_y)
            else:
                pdf.multi_cell(0, 5, "Nenhum dado na tabela.", 0, 'L')
        
        elif field_type == "Imagem":
            if isinstance(value, list) and value:
                for img_bytes in value:
                    try:
                        temp_img_path = f"temp_image_{uuid.uuid4().hex}.png"
                        with open(temp_img_path, "wb") as f: f.write(img_bytes)
                        pdf.image(temp_img_path, w=100); pdf.ln(2)
                        os.remove(temp_img_path)
                    except Exception as e:
                        pdf.multi_cell(0, 5, f"[Erro ao renderizar imagem: {e}]", 0, 'L')

        elif field_type == "Texto Longo":
            if isinstance(value, dict):
                if value.get("text"):
                    pdf.multi_cell(0, 5, clean_text(value["text"]), 0, 'L')
                if isinstance(value.get("images"), list) and value["images"]:
                    pdf.ln(2)
                    for img_bytes in value["images"]:
                        try:
                            temp_img_path = f"temp_image_{uuid.uuid4().hex}.png"
                            with open(temp_img_path, "wb") as f: f.write(img_bytes)
                            pdf.image(temp_img_path, w=100); pdf.ln(2)
                            os.remove(temp_img_path)
                        except Exception as e:
                            pdf.multi_cell(0, 5, f"[Erro ao renderizar imagem: {e}]", 0, 'L')
            else:
                pdf.multi_cell(0, 5, clean_text(value), 0, 'L')

        else:
            if isinstance(value, list): value_str = ", ".join(map(str, value))
            elif isinstance(value, bool): value_str = "Sim" if value else "N√£o"
            else: value_str = str(value)
            pdf.multi_cell(0, 5, clean_text(value_str), 0, 'L')
        
        pdf.ln(6)
        
    # --- IN√çCIO DA ALTERA√á√ÉO ---
    if os_data.get('items'):
        # Verifica se h√° espa√ßo para o t√≠tulo, cabe√ßalho e pelo menos uma linha
        if pdf.get_y() > pdf.page_break_trigger - 30:
            pdf.add_page()
            
        pdf.ln(5)
        pdf.set_font('Roboto', 'B', 12)
        pdf.cell(0, 10, 'Itens do Cat√°logo Inclusos', 0, 1, 'L')
        
        def draw_catalog_header():
            pdf.set_font('Roboto', 'B', 10)
            pdf.cell(160, 8, 'Item', 1, 0, 'C')
            pdf.cell(30, 8, 'Valor', 1, 1, 'C')
            pdf.set_font('Roboto', '', 10)

        draw_catalog_header()
        
        for item in os_data['items']:
            # Estima a altura necess√°ria para o texto do item
            item_text = clean_text(item.get('Item', ''))
            lines = pdf.multi_cell(160, 8, item_text, split_only=True)
            required_height = len(lines) * 8
            
            # Se a altura necess√°ria ultrapassar o limite da p√°gina, adiciona uma nova p√°gina e o cabe√ßalho
            if pdf.get_y() + required_height > pdf.page_break_trigger:
                pdf.add_page()
                draw_catalog_header()
            
            # Desenha a linha da tabela
            y_before = pdf.get_y()
            pdf.multi_cell(160, 8, item_text, border=1, align='L')
            y_after_item = pdf.get_y()
            pdf.set_xy(170, y_before)
            pdf.multi_cell(30, 8, clean_text(str(item.get('Valor', ''))), border=1, align='C', ln=1)
            y_after_valor = pdf.get_y()
            pdf.set_y(max(y_after_item, y_after_valor))
    # --- FIM DA ALTERA√á√ÉO ---
            
    if os_data.get('assinantes'):
        # Verifica se h√° espa√ßo para o t√≠tulo das assinaturas e pelo menos uma assinatura
        if pdf.get_y() > pdf.page_break_trigger - 50:
             pdf.add_page()

        pdf.ln(10)
        pdf.set_font('Roboto', 'B', 12)
        pdf.cell(0, 10, 'Assinaturas', 0, 1, 'L')
        pdf.ln(15)
        
        for assinante in os_data['assinantes']:
            if assinante.get('Nome') and assinante.get('Cargo'):
                # Verifica se h√° espa√ßo para uma assinatura completa
                if pdf.get_y() > pdf.page_break_trigger - 35:
                    pdf.add_page()
                    pdf.ln(10) # Adiciona espa√ßo no topo da nova p√°gina

                pdf.cell(0, 8, "___________________________________________", 0, 1, 'C')
                pdf.cell(0, 8, clean_text(f"{assinante['Nome']}"), 0, 1, 'C')
                pdf.cell(0, 8, clean_text(f"({assinante['Cargo']})"), 0, 1, 'C')
                pdf.ln(10)

    return bytes(pdf.output())

def create_dashboard_pdf(dashboard_name, charts_by_tab, df):
    """Gera um PDF do dashboard, com gr√°ficos como imagens."""
    pdf = PDF()
    pdf.os_title = f"Dashboard: {dashboard_name}"
    
    base_dir = Path(__file__).resolve().parent
    font_dir = base_dir / "fonts"
    pdf.add_font('Roboto', '', str(font_dir / "Roboto-Regular.ttf"))
    pdf.add_font('Roboto', 'B', str(font_dir / "Roboto-Bold.ttf"))
    
    pdf.add_page()

    for tab_name, charts in charts_by_tab.items():
        if not charts: continue
        
        if pdf.page_no() > 1 or pdf.get_y() > 40:
            pdf.add_page()

        pdf.set_font('Roboto', 'B', 18)
        pdf.cell(0, 10, f"Aba: {tab_name}", 0, 1, 'L')
        pdf.ln(5)

        for chart_config in charts:
            pdf.set_font('Roboto', 'B', 12)
            pdf.multi_cell(0, 8, f"üìä {chart_config.get('title', 'Gr√°fico sem t√≠tulo')}", 0, 'L')
            
            try:
                fig = render_chart(chart_config, df, return_fig=True)
                if fig:
                    img_bytes = fig.to_image(format="png", scale=2, width=800, height=450)
                    img_file = io.BytesIO(img_bytes)
                    
                    if pdf.get_y() + 80 > 297:
                        pdf.add_page()

                    pdf.image(img_file, w=180)
                    pdf.ln(10)
                else:
                    pdf.set_font('Roboto', '', 10)
                    pdf.set_text_color(255, 0, 0)
                    pdf.multi_cell(0, 5, "Nao foi possivel gerar uma imagem para este tipo de grafico (ex: Indicador).")
                    pdf.set_text_color(0, 0, 0)
                    pdf.ln(5)
            except Exception as e:
                pdf.set_font('Roboto', '', 10)
                pdf.set_text_color(255, 0, 0)
                error_type = type(e).__name__
                safe_error_message = f"Falha ao renderizar o grafico. Tipo de erro: {error_type}."
                pdf.multi_cell(0, 5, safe_error_message)
                pdf.set_text_color(0, 0, 0)
                pdf.ln(5)
                
    return pdf.output(dest='S').encode('latin-1')

# --- FUN√á√ÉO AUXILIAR PARA C√ÅLCULO DE KPI ---
def calculate_kpi_value(chart_config, df):
    op = chart_config.get('num_op')
    field = chart_config.get('num_field')
    data_frame = df
    if not op or not field: return None
    if field == 'Contagem de Issues':
        return len(data_frame)
    if field not in data_frame.columns: return None
    if op == 'Contagem': return len(data_frame.dropna(subset=[field]))
    numeric_series = pd.to_numeric(data_frame[field], errors='coerce')
    if numeric_series.isnull().all(): return None
    if op == 'Soma': return numeric_series.sum()
    if op == 'M√©dia': return numeric_series.mean()
    return None

# --- NOVA FUN√á√ÉO "LEITORA DE GR√ÅFICOS" PARA A IA ---
def summarize_chart_data(chart_config, df):
    """Gera um resumo em texto dos dados de um √∫nico gr√°fico."""
    title = chart_config.get('title', 'um gr√°fico')
    chart_type = chart_config.get('type')

    try:
        df_to_render = df.copy()
        chart_filters = chart_config.get('filters', [])
        if chart_filters:
            for f in chart_filters:
                field, op, val = f.get('field'), f.get('operator'), f.get('value')
                if field and op and val is not None and field in df_to_render.columns:
                    if op == '√© igual a': df_to_render = df_to_render[df_to_render[field] == val]
                    elif op == 'n√£o √© igual a': df_to_render = df_to_render[df_to_render[field] != val]
                    elif op == 'est√° em': df_to_render = df_to_render[df_to_render[field].isin(val)]
                    elif op == 'n√£o est√° em': df_to_render = df_to_render[~df_to_render[field].isin(val)]
                    elif op == 'maior que': df_to_render = df_to_render[pd.to_numeric(df_to_render[field], errors='coerce') > val]
                    elif op == 'menor que': df_to_render = df_to_render[pd.to_numeric(df_to_render[field], errors='coerce') < val]
                    elif op == 'entre' and len(val) == 2:
                        df_to_render = df_to_render[pd.to_numeric(df_to_render[field], errors='coerce').between(val[0], val[1])]

        if chart_type == 'indicator':
            if chart_config.get('source_type') == 'jql':
                return f"O indicador '{title}' √© calculado com uma consulta JQL personalizada."
            else:
                value = calculate_kpi_value(chart_config, df_to_render)
                if value is not None and pd.notna(value):
                    return f"O indicador '{title}' mostra o valor de {value:.1f}."
                else:
                    return f"O indicador '{title}' n√£o p√¥de ser calculado (N/A)."

        elif chart_type in ['barra', 'pizza']:
            dimension = chart_config.get('dimension'); measure = chart_config.get('measure'); agg = chart_config.get('agg', 'Soma')
            if not dimension or not measure: return None
            if measure == 'Contagem de Issues':
                summary_df = df_to_render.groupby(dimension).size().nlargest(5)
                return f"No gr√°fico '{title}', a contagem de issues por '{dimension}' revela que os 5 maiores grupos s√£o: {', '.join([f'{idx} ({val})' for idx, val in summary_df.items()])}."
            else:
                summary_df = df_to_render.groupby(dimension)[measure].agg(agg.lower()).nlargest(5)
                return f"No gr√°fico '{title}', a {agg.lower()} de '{measure}' por '{dimension}' revela que os 5 maiores grupos s√£o: {', '.join([f'{idx} ({val:.1f})' for idx, val in summary_df.items()])}."

        elif chart_type == 'linha':
            x_col, y_col = chart_config['x'], chart_config['y']
            plot_df = df_to_render.dropna(subset=[x_col, y_col])
            if len(plot_df) > 2:
                X = np.array(range(len(plot_df))).reshape(-1, 1); y = plot_df[y_col]
                model = LinearRegression().fit(X, y)
                trend = "de subida" if model.coef_[0] > 0 else "de descida"
                return f"O gr√°fico de linha '{title}' mostra '{y_col}' ao longo de '{x_col}', com uma tend√™ncia geral {trend}."

        return f"Dados para o gr√°fico '{title}' do tipo {chart_type}."
    except Exception:
        return f"N√£o foi poss√≠vel processar os dados para o gr√°fico '{title}'."

# --- FUN√á√ïES DE IA ---
def _get_ai_client_and_model(provider, user_data):
    """Fun√ß√£o auxiliar para configurar e retornar o cliente de IA correto."""
    api_key_encrypted = None
    if provider == "Google Gemini":
        api_key_encrypted = user_data.get('encrypted_gemini_key')
        if not api_key_encrypted:
            st.warning("Nenhuma chave de API do Gemini configurada.", icon="üîë")
            st.info("Para usar esta funcionalidade, por favor, adicione a sua chave na p√°gina 'Minha Conta'.")
            st.page_link("pages/9_üë§_Minha_Conta.py", label="Configurar Chave de IA Agora", icon="ü§ñ")
            return None
        try:
            api_key = decrypt_token(api_key_encrypted)
            genai.configure(api_key=api_key)
            model_name = user_data.get('ai_model_preference', 'gemini-1.5-flash-latest')
            return genai.GenerativeModel(model_name)
        except Exception as e:
            st.error(f"Erro com a API do Gemini: {e}"); return None

    elif provider == "OpenAI (ChatGPT)":
        api_key_encrypted = user_data.get('encrypted_openai_key')
        if not api_key_encrypted:
            st.warning("Nenhuma chave de API da OpenAI configurada.", icon="üîë")
            st.info("Para usar esta funcionalidade, por favor, adicione a sua chave na p√°gina 'Minha Conta'.")
            st.page_link("pages/9_üë§_Minha_Conta.py", label="Configurar Chave de IA Agora", icon="ü§ñ")
            return None
        try:
            api_key = decrypt_token(api_key_encrypted)
            return openai.OpenAI(api_key=api_key)
        except Exception as e:
            st.error(f"Erro com a API da OpenAI: {e}"); return None
    return None

def get_ai_insights(project_name, chart_summaries, provider):
    """Chama a API de IA preferida do utilizador para gerar insights do dashboard."""
    user_data = find_user(st.session_state['email'])
    model_client = _get_ai_client_and_model(provider, user_data)
    if not model_client: return None

    prompt = f"""
    Aja como um Analista de Neg√≥cios especialista em projetos de software e metodologias √°geis.
    O seu trabalho √© analisar os dados de um dashboard do Jira para o projeto "{project_name}" e fornecer um resumo executivo em portugu√™s.

    Aqui est√£o os dados resumidos de cada gr√°fico no dashboard:
    {chr(10).join(f"- {s}" for s in chart_summaries if s)}

    Com base nestes dados, gere uma an√°lise concisa e acion√°vel. A sua resposta deve ser formatada em Markdown e dividida nas seguintes sec√ß√µes:
    1.  **üéØ Pontos Fortes:** O que os dados indicam que est√° a correr bem? Seja espec√≠fico.
    2.  **‚ö†Ô∏è Pontos de Aten√ß√£o:** Onde podem estar os riscos, gargalos ou desvios? Aponte as m√©tricas preocupantes.
    3.  **üöÄ Recomenda√ß√µes:** Sugira 1 a 2 a√ß√µes pr√°ticas que a equipa ou o gestor do projeto poderiam tomar com base nesta an√°lise.
    """

    try:
        if provider == "Google Gemini":
            response = model_client.generate_content(prompt)
            return response.text
        else: # OpenAI
            response = model_client.chat.completions.create(model="gpt-4o", messages=[{"role": "user", "content": prompt}])
            return response.choices[0].message.content
    except openai.RateLimitError:
        st.error(
            """
            **Sua quota de utiliza√ß√£o da API da OpenAI foi excedida.** üòü
            Isto geralmente acontece quando os cr√©ditos gratuitos expiram ou o seu limite de fatura√ß√£o √© atingido.
            **O que fazer?**
            1. Aceda ao seu painel da [OpenAI Platform](https://platform.openai.com/account/billing/overview).
            2. Verifique a sua sec√ß√£o de **"Billing" (Fatura√ß√£o)** para adicionar um m√©todo de pagamento ou aumentar os seus limites.
            Enquanto isso, voc√™ pode ir √† sua p√°gina **'Minha Conta'** e mudar o seu provedor de IA para o **Google Gemini**.
            """,
            icon="üí≥"
        )
        return None
    except openai.AuthenticationError:
        st.error("A sua chave de API da OpenAI √© inv√°lida ou foi revogada. Por favor, verifique-a na p√°gina 'Minha Conta'.", icon="üîë")
        return None
    except Exception as e:
        st.error(f"Ocorreu um erro inesperado com a API da OpenAI: {e}"); return None

def generate_chart_config_from_text(prompt, numeric_cols, categorical_cols, active_filters=None):
    """
    Usa a API de IA para gerar uma configura√ß√£o de gr√°fico e aplica os filtros ativos.
    Vers√£o final com prompt aprimorado e verifica√ß√£o de seguran√ßa.
    """
    user_data = find_user(st.session_state['email'])
    provider = user_data.get('ai_provider_preference', 'Google Gemini')

    model_client = _get_ai_client_and_model(provider, user_data)
    if not model_client:
        return None, "A sua chave de API n√£o est√° configurada ou √© inv√°lida."

    # --- PROMPT DE ENGENHARIA MELHORADO ---
    system_prompt = f"""
    Aja como um especialista em Business Intelligence. A sua tarefa √© converter um pedido de utilizador em linguagem natural para um objeto JSON que define uma visualiza√ß√£o.

    O utilizador tem acesso aos seguintes campos:
    - Campos Categ√≥ricos (para dimens√µes): {', '.join(categorical_cols)}
    - Campos Num√©ricos (para medidas): {', '.join(numeric_cols)}

    **Regras para a convers√£o:**
    1.  **Primeiro, identifique a inten√ß√£o:**
        - Se o pedido for uma pergunta que resulta num **n√∫mero √∫nico** (ex: "qual o total de issues?", "quantos bugs abertos?"), gere um **Indicador (KPI)**.
        - Se o pedido mencionar explicitamente "tabela", gere uma **Tabela**.
        - Para todos os outros casos (ex: "issues por status"), gere um **Gr√°fico Agregado**.

    2.  **Estruturas JSON:**
        - **KPI:** `{{"creator_type": "Indicador (KPI)", "type": "indicator", "style": "N√∫mero Grande", "title": "...", "num_op": "...", "num_field": "..."}}`
        - **Tabela:** `{{"creator_type": "Gr√°fico Agregado", "type": "tabela", "title": "...", "columns": ["campo1", "campo2"]}}`
        - **Gr√°fico Agregado:** `{{"creator_type": "Gr√°fico Agregado", "type": "barra", "dimension": "...", "measure": "...", "agg": "...", "title": "..."}}`

    3.  **Regras de Preenchimento:**
        - **IMPORTANTE:** Se o c√°lculo for uma contagem, a 'measure' ou 'num_field' DEVE ser a string exata "Contagem de Issues".
        - Se o pedido n√£o especificar uma dimens√£o para um gr√°fico, voc√™ DEVE retornar uma mensagem de erro.

    Responda APENAS com o objeto JSON.
    """
    full_prompt = f"{system_prompt}\n\nPedido do Utilizador: \"{prompt}\""

    try:
        if provider == "Google Gemini":
            response = model_client.generate_content(full_prompt)
            cleaned_response = response.text.strip().replace("```json", "").replace("```", "")
        else: # OpenAI
            response = model_client.chat.completions.create(model="gpt-4o", messages=[{"role": "user", "content": full_prompt}], response_format={"type": "json_object"})
            cleaned_response = response.choices[0].message.content

        if not cleaned_response:
            return None, "A IA n√£o conseguiu gerar uma configura√ß√£o v√°lida. Tente reformular o seu pedido."

        chart_config = json.loads(cleaned_response)

        # --- VERIFICA√á√ÉO DE SEGURAN√áA ---
        # Se a IA gerou um gr√°fico agregado sem dimens√£o, corrige para um KPI.
        if chart_config.get('type') in ['barra', 'pizza', 'linha_agregada'] and not chart_config.get('dimension'):
            st.warning("A IA interpretou o seu pedido como um gr√°fico, mas n√£o encontrou uma dimens√£o. A exibir o total como um KPI.")
            chart_config = {
                'creator_type': 'Indicador (KPI)', 'type': 'indicator',
                'style': 'N√∫mero Grande', 'title': prompt,
                'num_op': 'Contagem', 'num_field': 'Contagem de Issues'
            }

        chart_config['filters'] = active_filters if active_filters else []
        chart_config['id'] = str(uuid.uuid4())
        chart_config['source_type'] = 'visual'

        return chart_config, None
    except Exception as e:
        return None, f"Ocorreu um erro ao comunicar com a IA: {e}"

def generate_risk_analysis_with_ai(project_name, metrics_summary):
    """
    Usa a API de IA preferida do utilizador para analisar um resumo de m√©tricas
    e gerar uma lista de descri√ß√µes de riscos potenciais.
    """
    user_data = find_user(st.session_state['email'])
    provider = user_data.get('ai_provider_preference', 'Google Gemini')

    prompt = f"""
    Aja como um Agile Coach especialista. Analise o seguinte resumo de m√©tricas do projeto "{project_name}":
    {metrics_summary}

    Com base nestes dados, identifique 2 a 3 riscos ou pontos de aten√ß√£o cr√≠ticos.
    A sua resposta deve ser uma lista de descri√ß√µes de riscos, formatada como um JSON array de strings.
    Exemplo de resposta: ["O Lead Time m√©dio est√° a aumentar, o que pode indicar gargalos no in√≠cio do fluxo.", "A baixa taxa de entregas no √∫ltimo m√™s sugere uma poss√≠vel sobrecarga da equipa ou bloqueios externos."]
    Responda APENAS com o JSON array.
    """

    try:
        if provider == "Google Gemini":
            api_key = decrypt_token(user_data['encrypted_gemini_key'])
            genai.configure(api_key=api_key)
            model_name = user_data.get('ai_model_preference', 'gemini-1.5-flash-latest')
            model = genai.GenerativeModel(model_name)
            response = model.generate_content(prompt)
            # Limpa a resposta para garantir que √© um JSON v√°lido
            cleaned_response = response.text.strip().replace("```json", "").replace("```", "")
            return json.loads(cleaned_response)

        elif provider == "OpenAI (ChatGPT)":
            api_key = decrypt_token(user_data['encrypted_openai_key'])
            client = openai.OpenAI(api_key=api_key)
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "Responda apenas com um JSON array de strings."},
                    {"role": "user", "content": prompt}
                ],
                response_format={"type": "json_object"} # Pede √† OpenAI para for√ßar a sa√≠da em JSON
            )
            # A resposta da OpenAI pode vir num formato ligeiramente diferente, ajuste se necess√°rio
            return json.loads(response.choices[0].message.content)

    except Exception as e:
        st.error(f"Erro ao gerar an√°lise de riscos: {e}")
        return [f"Erro na comunica√ß√£o com a API: {e}"]

def generate_ai_risk_assessment(project_name, metrics_summary):
    """
    Usa a API de IA preferida do utilizador para analisar m√©tricas e gerar
    um n√≠vel de risco e uma lista de descri√ß√µes de riscos.
    """
    user_data = find_user(st.session_state['email'])
    provider = user_data.get('ai_provider_preference', 'Google Gemini')

    prompt = f"""
    Aja como um Gestor de Projetos S√™nior. Analise o seguinte resumo de m√©tricas do projeto "{project_name}":
    {metrics_summary}

    Com base nestes dados, fa√ßa o seguinte:
    1.  Classifique o N√≠vel de Risco geral do projeto como "Baixo", "Moderado", "Alto" ou "Cr√≠tico".
    2.  Identifique de 2 a 3 riscos ou pontos de aten√ß√£o cr√≠ticos que justificam essa classifica√ß√£o.

    A sua resposta deve ser um objeto JSON com a seguinte estrutura:
    {{
      "risk_level": "Seu N√≠vel de Risco aqui",
      "risks": [
        "Descri√ß√£o detalhada do primeiro risco.",
        "Descri√ß√£o detalhada do segundo risco."
      ]
    }}
    Responda APENAS com o objeto JSON.
    """

    try:
        if provider == "Google Gemini":
            api_key = decrypt_token(user_data['encrypted_gemini_key'])
            genai.configure(api_key=api_key)
            model_name = user_data.get('ai_model_preference', 'gemini-1.5-flash-latest')
            model = genai.GenerativeModel(model_name)
            response = model.generate_content(prompt)
            cleaned_response = response.text.strip().replace("```json", "").replace("```", "")
            return json.loads(cleaned_response)

        elif provider == "OpenAI (ChatGPT)":
            api_key = decrypt_token(user_data['encrypted_openai_key'])
            client = openai.OpenAI(api_key=api_key)
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "Responda apenas com um objeto JSON v√°lido."},
                    {"role": "user", "content": prompt}
                ],
                response_format={"type": "json_object"}
            )
            return json.loads(response.choices[0].message.content)

    except Exception as e:
        st.error(f"Erro ao gerar an√°lise de riscos: {e}")
        return {"risk_level": "Erro", "risks": [f"Erro na comunica√ß√£o com a API: {e}"]}

def get_ai_rag_status(project_name, metrics_summary):
    """
    Usa a API de IA preferida do utilizador para analisar m√©tricas e determinar
    um status RAG para o projeto.
    """
    user_data = find_user(st.session_state['email'])
    provider = user_data.get('ai_provider_preference', 'Google Gemini')
    model_client = _get_ai_client_and_model(provider, user_data)
    if not model_client: return "An√°lise indispon√≠vel. Verifique a configura√ß√£o da sua chave de IA."

    prompt = f"""
    Aja como um Diretor de Projetos (PMO). Analise o seguinte resumo de m√©tricas do projeto "{project_name}":
    {metrics_summary}

    Com base nestes dados, classifique o status do projeto em UMA das seguintes quatro categorias:
    "üü¢ No prazo", "üü° Atraso moderado", "üî¥ Atrasado", "‚ö™ N√£o definido".

    Use o seguinte crit√©rio:
    - Se o percentual conclu√≠do for alto e o desvio de prazo for negativo ou pr√≥ximo de zero, o status √© "üü¢ No prazo".
    - Se o percentual conclu√≠do for m√©dio e o desvio de prazo for positivo, mas pequeno, o status √© "üü° Atraso moderado".
    - Se o percentual conclu√≠do for baixo e o desvio de prazo for significativamente positivo, o status √© "üî¥ Atrasado".
    - Se os dados forem insuficientes para uma conclus√£o, use "‚ö™ N√£o definido".

    Responda APENAS com a string da categoria escolhida, sem nenhuma outra palavra.
    """

    try:
        if provider == "Google Gemini":
            response = model_client.generate_content(prompt)
            return response.text.strip()

        elif provider == "OpenAI (ChatGPT)":
            api_key = decrypt_token(user_data['encrypted_openai_key'])
            client = openai.OpenAI(api_key=api_key)
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "Responda apenas com a string da categoria escolhida."},
                    {"role": "user", "content": prompt}
                ]
            )
            return response.choices[0].message.content.strip()

    except Exception as e:
        st.error(f"Erro ao gerar status RAG: {e}")
        return "‚ö™ Erro"

def combined_dimension_ui(df, categorical_cols, date_cols, key_suffix=""):
    """
    Cria a interface para o utilizador definir uma dimens√£o combinada e retorna
    o novo nome da dimens√£o e um dataframe com a nova coluna.
    """
    st.info("Selecione dois campos para criar uma dimens√£o combinada (ex: 'Data de Conclus√£o - Status').", icon="üîó")

    c1, c2, c3 = st.columns(3)

    field1_options = [""] + date_cols + categorical_cols
    field2_options = [""] + categorical_cols + date_cols

    field1 = c1.selectbox("Campo 1", options=field1_options, key=f"combo_field1_{key_suffix}")
    separator = c2.text_input("Separador", value=" - ", key=f"combo_sep_{key_suffix}")
    field2 = c3.selectbox("Campo 2", options=field2_options, key=f"combo_field2_{key_suffix}")

    if field1 and field2:
        new_dimension_name = f"{field1}{separator}{field2}"
        df_copy = df.copy()

        field1_str = pd.to_datetime(df_copy[field1]).dt.strftime('%Y-%m-%d') if field1 in date_cols else df_copy[field1].astype(str).fillna('')
        field2_str = pd.to_datetime(df_copy[field2]).dt.strftime('%Y-%m-%d') if field2 in date_cols else df_copy[field2].astype(str).fillna('')

        df_copy[new_dimension_name] = field1_str + separator + field2_str
        return new_dimension_name, df_copy

    return None, df


def get_ai_forecast_analysis(project_name, scope_total, completed_pct, avg_velocity, trend_velocity, forecast_date_str):
    """Gera um resumo de forecast usando a IA configurada."""
    user_data = find_user(st.session_state['email'])
    provider = user_data.get('ai_provider_preference', 'Google Gemini')
    model_client = _get_ai_client_and_model(provider, user_data)
    if not model_client: return "An√°lise indispon√≠vel. Verifique a configura√ß√£o da sua chave de IA."

    metrics_summary = f"- Escopo Total: {scope_total}\n- Percentual Conclu√≠do: {completed_pct}%\n- Velocidade M√©dia: {avg_velocity:.1f}/semana\n- Velocidade de Tend√™ncia: {trend_velocity:.1f}/semana\n- Previs√£o de Conclus√£o: {forecast_date_str}"
    prompt = f"Aja como um Gestor de Projetos. Analise as m√©tricas do projeto '{project_name}':\n{metrics_summary}\n\nEscreva um par√°grafo de 'Resumo Executivo' a avaliar a sa√∫de, acelera√ß√£o e realismo da previs√£o de entrega."

    try:
        if provider == "Google Gemini":
            response = model_client.generate_content(prompt)
            return response.text
        else: # OpenAI
            response = model_client.chat.completions.create(model="gpt-4o", messages=[{"role": "user", "content": prompt}])
            return response.choices[0].message.content
    except Exception as e:
        return f"Erro ao gerar a an√°lise de forecast: {e}"

def get_ai_planning_analysis(project_name, remaining_work, remaining_weeks, required_throughput, trend_velocity, people_needed, current_team_size):
    """
    Usa a API de IA preferida do utilizador para analisar um cen√°rio de planeamento
    e gerar uma an√°lise de viabilidade, combinando a l√≥gica de prompt detalhada
    com a gest√£o de chaves centralizada.
    """
    user_data = find_user(st.session_state['email'])
    provider = user_data.get('ai_provider_preference', 'Google Gemini')

    # 1. Obt√©m o cliente de IA de forma segura atrav√©s da fun√ß√£o central
    model_client = _get_ai_client_and_model(provider, user_data)
    if not model_client:
        return "An√°lise indispon√≠vel. Verifique a configura√ß√£o da sua chave de IA."

    # 2. Constr√≥i o resumo das m√©tricas e o prompt detalhado
    metrics_summary = f"""
    - Trabalho Restante: {remaining_work}
    - Semanas Restantes at√© a meta: {remaining_weeks:.1f}
    - Vaz√£o (Throughput) Necess√°ria: {required_throughput:.1f} por semana
    - Vaz√£o de Tend√™ncia (performance recente): {trend_velocity:.1f} por semana
    - Pessoas Necess√°rias (estimativa): {people_needed}
    - Tamanho da Equipa Atual: {current_team_size}
    """

    prompt = f"""
    Aja como um Agile Coach S√™nior. Analise o seguinte cen√°rio de planeamento de entrega para o projeto "{project_name}":
    {metrics_summary}

    Com base nesta compara√ß√£o entre o necess√°rio e o hist√≥rico, escreva um par√°grafo de "An√°lise de Viabilidade". O seu texto deve ser conciso e focado em responder √†s seguintes perguntas:
    1.  O plano √© realista? Compare a "Vaz√£o Necess√°ria" com a "Vaz√£o de Tend√™ncia".
    2.  Quais s√£o os principais riscos se a vaz√£o necess√°ria for muito maior que a tend√™ncia? (Ex: risco de burnout, queda na qualidade).
    3.  Com base na estimativa de "Pessoas Necess√°rias" vs. o tamanho atual da equipa, qual √© a sua recomenda√ß√£o? (Ex: "o plano √© vi√°vel com a equipa atual", "o plano exige recursos adicionais", etc.).

    Seja direto e use uma linguagem clara e profissional.
    """

    # 3. Chama a API correta e retorna a resposta
    try:
        if provider == "Google Gemini":
            response = model_client.generate_content(prompt)
            return response.text
        elif provider == "OpenAI (ChatGPT)":
            response = model_client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "Aja como um Agile Coach S√™nior."},
                    {"role": "user", "content": prompt}
                ]
            )
            return response.choices[0].message.content
    except Exception as e:
        st.error(f"Erro ao gerar a an√°lise de planeamento: {e}")
        return "N√£o foi poss√≠vel gerar a an√°lise de planeamento."

def get_field_value(issue, field_config):
    """
    Fun√ß√£o inteligente que extrai o valor de qualquer campo do Jira,
    independentemente do seu tipo (texto, lista, objeto, etc.).
    """
    field_id = field_config.get('id')
    if not field_id:
        return None

    value = getattr(issue.fields, field_id, None)

    if value is None:
        return None

    # L√≥gica para os diferentes tipos de objeto do Jira
    if hasattr(value, 'displayName'): return value.displayName # Para campos de Utilizador
    if hasattr(value, 'value'): return value.value           # Para campos de Lista de Sele√ß√£o
    if hasattr(value, 'name'): return value.name             # Para campos de Objeto Simples (Status, Priority)
    if isinstance(value, list):
        return ', '.join([getattr(v, 'name', str(v)) for v in value]) # Para listas

    # Se for um tipo simples (texto, n√∫mero, data)
    return str(value).split('T')[0]

def send_email_with_attachment(to_address, subject, body, attachment_bytes, attachment_filename):
    """
    Fun√ß√£o central para enviar e-mails com anexo, com base no provedor
    configurado pelo utilizador na sua conta.
    """
    # Busca as configura√ß√µes da mem√≥ria da sess√£o, que foram carregadas no login
    smtp_configs = st.session_state.get('smtp_configs')
    if not smtp_configs or not smtp_configs.get('provider'):
        return False, "Nenhuma configura√ß√£o de e-mail encontrada na sua conta."

    provider = smtp_configs['provider']

    if provider == 'SendGrid':
        try:
            # Usa a chave de API desencriptada
            api_key = decrypt_token(smtp_configs['api_key_encrypted'])
            sg = sendgrid.SendGridAPIClient(api_key)

            from_email = smtp_configs['from_email']
            message = Mail(from_email=from_email, to_emails=to_address, subject=subject, html_content=body)

            encoded_file = base64.b64encode(attachment_bytes).decode()
            attachedFile = Attachment(
                FileContent(encoded_file),
                FileName(attachment_filename),
                FileType('application/pdf'),
                Disposition('attachment')
            )
            message.attachment = attachedFile

            response = sg.send(message)
            if response.status_code in [200, 202]:
                return True, "E-mail enviado com sucesso via SendGrid!"
            else:
                return False, f"Falha ao enviar e-mail via SendGrid: Status {response.status_code}"
        except Exception as e:
            return False, f"Ocorreu um erro ao enviar e-mail via SendGrid: {e}"

    elif provider == 'Gmail (SMTP)':
        try:
            # Usa a senha de aplica√ß√£o desencriptada
            app_password = decrypt_token(smtp_configs['app_password_encrypted'])
            from_email = smtp_configs['from_email']

            smtp_server = smtplib.SMTP_SSL('smtp.gmail.com', 465)
            smtp_server.login(from_email, app_password)

            msg = MIMEMultipart()
            msg['From'] = from_email
            msg['To'] = to_address
            msg['Subject'] = subject
            msg.attach(MIMEText(body, 'plain'))

            attachment = MIMEApplication(attachment_bytes, _subtype="pdf")
            attachment.add_header('Content-Disposition', 'attachment', filename=attachment_filename)
            msg.attach(attachment)

            smtp_server.sendmail(from_email, to_address, msg.as_string())
            smtp_server.quit()
            return True, "E-mail enviado com sucesso via Gmail!"
        except Exception as e:
            return False, f"Ocorreu um erro ao enviar e-mail via SMTP: {e}"

    return False, "Provedor de e-mail n√£o configurado ou inv√°lido."

def send_notification_email(to_address, subject, body_html):
    """Envia um e-mail de notifica√ß√£o formatado em HTML."""
    try:
        sender_email = st.secrets["gmail_smtp"]["EMAIL_ADDRESS"]
        sender_password = st.secrets["gmail_smtp"]["EMAIL_PASSWORD"]

        msg = MIMEMultipart()
        msg['From'] = sender_email
        msg['To'] = to_address
        msg['Subject'] = subject
        msg.attach(MIMEText(body_html, 'html'))

        server = smtplib.SMTP('smtp.gmail.com', 587)
        server.starttls()
        server.login(sender_email, sender_password)
        server.send_message(msg)
        server.quit()

        return True, "Notifica√ß√£o enviada com sucesso!"
    except Exception as e:
        # Em produ√ß√£o, voc√™ pode querer logar o erro em vez de o exibir
        print(f"Falha ao enviar a notifica√ß√£o: {e}")
        return False, f"Falha ao enviar a notifica√ß√£o: {e}"

def send_email_with_attachment(to_address, subject, body, attachment_bytes=None, attachment_filename=None):
    """Envia um e-mail com um anexo."""
    try:
        sender_email = st.secrets["gmail_smtp"]["EMAIL_ADDRESS"]
        sender_password = st.secrets["gmail_smtp"]["EMAIL_PASSWORD"]

        msg = MIMEMultipart()
        msg['From'] = sender_email
        msg['To'] = to_address
        msg['Subject'] = subject
        msg.attach(MIMEText(body, 'plain'))

        if attachment_bytes and attachment_filename:
            part = MIMEApplication(attachment_bytes, Name=attachment_filename)
            part['Content-Disposition'] = f'attachment; filename="{attachment_filename}"'
            msg.attach(part)

        server = smtplib.SMTP('smtp.gmail.com', 587)
        server.starttls()
        server.login(sender_email, sender_password)
        server.send_message(msg)
        server.quit()

        return True, "E-mail enviado com sucesso!"
    except Exception as e:
        return False, f"Falha ao enviar o e-mail: {e}"

# --- NOVAS FUN√á√ïES DE VALIDA√á√ÉO ---
def is_valid_url(url):
    """Verifica se uma string corresponde ao formato de um URL."""
    # Express√£o regular simples para validar URLs
    regex = re.compile(
        r'^(?:http|ftp)s?://' # http:// or https://
        r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\.)+(?:[A-Z]{2,6}\.?|[A-Z0-9-]{2,}\.?)|' # domain...
        r'localhost|' # localhost...
        r'\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})' # ...or ip
        r'(?::\d+)?' # optional port
        r'(?:/?|[/?]\S+)$', re.IGNORECASE)
    return re.match(regex, url) is not None

def is_valid_email(email):
    """Verifica se uma string corresponde ao formato de um e-mail."""
    # Express√£o regular para validar e-mails
    regex = re.compile(r'([A-Za-z0-9]+[.-_])*[A-Za-z0-9]+@[A-Za-z0-9-]+(\.[A-Z|a-z]{2,})+')
    return re.fullmatch(regex, email)

# --- FUN√á√ÉO CENTRAL DE CARREGAMENTO DE DADOS ---
def load_and_process_project_data(jira_client, project_key):
    """
    Busca todas as issues de um projeto no Jira, processa os campos din√¢micos
    e retorna um DataFrame pronto para an√°lise.
    """
    with st.spinner(f"A carregar e processar dados do projeto..."):
        all_issues_raw = get_all_project_issues(jira_client, project_key)
        st.session_state['raw_issues_for_fluxo'] = all_issues_raw
        valid_issues = filter_ignored_issues(all_issues_raw)

        data = []
        user_data = find_user(st.session_state['email'])
        global_configs = st.session_state.get('global_configs', {})
        project_config = get_project_config(project_key) or {}

        user_enabled_standard = user_data.get('standard_fields', [])
        user_enabled_custom = user_data.get('enabled_custom_fields', [])
        all_available_standard = global_configs.get('available_standard_fields', {})
        all_available_custom = global_configs.get('custom_fields', [])
        estimation_config = project_config.get('estimation_field', {})

        fields_to_process = []
        for field_name in user_enabled_standard:
            if field_name in all_available_standard:
                fields_to_process.append({**all_available_standard[field_name], 'name': field_name})
        for field_config in all_available_custom:
            if field_config.get('name') in user_enabled_custom:
                fields_to_process.append(field_config)

        for i in valid_issues:
            completion_date = find_completion_date(i, project_config)
            issue_data = {
                'Issue': i.key,
                'Data de Cria√ß√£o': pd.to_datetime(i.fields.created).tz_localize(None),
                'Data de Conclus√£o': completion_date,
                'Lead Time (dias)': calculate_lead_time(i, completion_date),
                'Cycle Time (dias)': calculate_cycle_time(i, completion_date, project_config), # <-- CORRE√á√ÉO AQUI
                'Tempo Gasto (Horas)': (i.fields.timespent or 0) / 3600
            }

            for field in fields_to_process:
                issue_data[field['name']] = get_field_value(i, field)

            if estimation_config.get('id'):
                issue_data[estimation_config['name']] = get_issue_estimation(i, estimation_config)

            data.append(issue_data)

        return pd.DataFrame(data)

def get_ai_product_vision(project_name, issues_data):
    """
    Usa a IA para analisar uma lista de issues e gerar uma vis√£o de produto,
    identificando gaps e sugerindo melhorias.
    """
    user_data = find_user(st.session_state['email'])
    provider = user_data.get('ai_provider_preference', 'Google Gemini')

    model_client = _get_ai_client_and_model(provider, user_data)
    if not model_client:
        return "An√°lise indispon√≠vel. Verifique a configura√ß√£o da sua chave de IA."

    # Prepara um resumo dos dados para enviar √† IA
    tasks_summary = "\n".join([f"- {item['Tipo']}: {item['T√≠tulo']} (Labels: {item['Labels']})" for item in issues_data])

    prompt = f"""
    Aja como um Diretor de Produto experiente. A sua tarefa √© analisar uma lista de tarefas (issues) do projeto "{project_name}" e gerar uma an√°lise estrat√©gica de produto em portugu√™s.

    **Dados das Tarefas Analisadas:**
    {tasks_summary}

    **A sua an√°lise deve seguir estritamente a seguinte estrutura em Markdown:**

    ### üîÆ Vis√£o Geral do Produto
    (Fa√ßa um resumo de 2-3 frases sobre o foco atual do produto, com base nos tipos de tarefas que est√£o a ser desenvolvidas.)

    ### üìä An√°lise da Natureza do Trabalho
    (Classifique o esfor√ßo da equipa. Estime, em percentagem, quanto do trabalho parece ser dedicado a: **Valor para o Usu√°rio** (novas features), **Manuten√ß√£o do Neg√≥cio** (bugs, d√©bitos t√©cnicos) e **Inova√ß√£o** (pesquisas, provas de conceito). Justifique a sua estimativa.)

    ### üîç Gaps e Oportunidades Identificados
    (Com base nas tarefas, identifique 2 a 3 "gaps" ou oportunidades que parecem estar a ser negligenciadas. Ex: "Parece haver pouco foco na experi√™ncia de novos utilizadores (onboarding)", ou "O grande n√∫mero de bugs no m√≥dulo de pagamentos sugere uma oportunidade de refatora√ß√£o para aumentar a estabilidade".)

    ### üöÄ Recomenda√ß√µes Estrat√©gicas
    (Sugira 2 a√ß√µes pr√°ticas e de alto impacto que a equipa de produto poderia tomar. As sugest√µes devem ser baseadas diretamente nos gaps que voc√™ identificou.)
    """

    try:
        if provider == "Google Gemini":
            response = model_client.generate_content(prompt)
            return response.text
        else: # OpenAI
            response = model_client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "Aja como um Diretor de Produto experiente."},
                    {"role": "user", "content": prompt}
                ]
            )
            return response.choices[0].message.content
    except Exception as e:
        return f"Ocorreu um erro ao gerar a an√°lise de produto: {e}"

# utils.py
import streamlit as st
# ... (outros imports existentes)

# ... (Sua fun√ß√£o auxiliar _get_ai_client_and_model e as outras fun√ß√µes de IA permanecem aqui) ...

def get_ai_strategic_diagnosis(project_name, client_name, issues_data, flow_metrics_summary, project_profile_summary, contextual_projects_summary=None):
    """
    Usa a IA para analisar o ecossistema de um projeto focado num cliente espec√≠fico,
    retornando um objeto JSON estruturado.
    """
    user_data = find_user(st.session_state['email'])
    provider = user_data.get('ai_provider_preference', 'Google Gemini')

    model_client = _get_ai_client_and_model(provider, user_data)
    if not model_client:
        return {"error": "An√°lise indispon√≠vel. Verifique a configura√ß√£o da sua chave de IA."}

    tasks_summary_text = "\n".join([f"- {item['Tipo']}: {item['T√≠tulo']}" for item in issues_data[:20]])
    context_text = "\n".join([f"- {summary}" for summary in contextual_projects_summary]) if contextual_projects_summary else "Nenhum"

    prompt = f"""
    Aja como um Diretor de Contas de uma consultoria de TI. A sua tarefa √© analisar a sa√∫de da conta do cliente "{client_name}", que est√° associada ao projeto "{project_name}", e gerar um diagn√≥stico estrat√©gico em formato JSON.

    **Contexto da Conta (Dados inseridos manualmente para este cliente):**
    {project_profile_summary}

    **Performance Operacional (M√©tricas do projeto principal para este cliente):**
    {flow_metrics_summary}

    **Contexto de Gest√£o (Tarefas de gest√£o relacionadas a este cliente, de outros projetos):**
    {context_text}

    **Amostra de Tarefas de Desenvolvimento Recentes:**
    {tasks_summary_text}

    **A sua an√°lise deve cruzar todas estas fontes de dados e seguir estritamente a seguinte estrutura JSON:**

    {{"diagnostico_estrategico": "(Resumo 2-3 frases a conectar os objetivos do neg√≥cio com a performance operacional)", "analise_natureza_trabalho": "(An√°lise da natureza do trabalho e alinhamento com a estrat√©gia)", "plano_de_acao_recomendado": "(Sugest√µes de 2 a√ß√µes estrat√©gicas e pr√°ticas)"}}
    """
    try:
        if provider == "Google Gemini":
            response = model_client.generate_content(prompt)
            cleaned_response = response.text.strip().replace("```json", "").replace("```", "")
        else: # OpenAI
            response = model_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": prompt}],
                response_format={"type": "json_object"}
            )
            cleaned_response = response.choices[0].message.content

        return json.loads(cleaned_response)
    except Exception as e:
        return {"error": f"Ocorreu um erro ao gerar o diagn√≥stico: {e}"}

def get_ai_chat_response(initial_diagnosis, chat_history, user_question, issues_context):
    """
    Usa a IA para responder a uma pergunta de seguimento, com acesso √† lista de issues
    que originaram a an√°lise.
    """
    user_data = find_user(st.session_state['email'])
    provider = user_data.get('ai_provider_preference', 'Google Gemini')

    model_client = _get_ai_client_and_model(provider, user_data)
    if not model_client:
        return "N√£o consigo responder agora. Verifique a configura√ß√£o da sua chave de IA."

    # Prepara um resumo das issues para o contexto
    issues_summary = "\n".join([
        f"- Chave: {item['Key']}, T√≠tulo: {item['T√≠tulo']}, Status: {item['Status']}, Respons√°vel: {item['Respons√°vel']}"
        for item in issues_context
    ])

    history_for_prompt = "\n".join([f"- {msg['role']}: {msg['content']}" for msg in chat_history])

    prompt = f"""
    Aja como o mesmo Consultor de Produto que escreveu a an√°lise abaixo. A sua tarefa √© responder a uma pergunta de seguimento do utilizador.
    Voc√™ tem acesso √† lista completa de issues que foram usadas para gerar a an√°lise. Use esta lista para encontrar exemplos espec√≠ficos e dados concretos para justificar as suas respostas.

    **Diagn√≥stico Inicial (Contexto Principal):**
    {initial_diagnosis}

    **Dados das Issues (Use para pesquisar e encontrar exemplos):**
    {issues_summary}

    **Hist√≥rico da Conversa:**
    {history_for_prompt}

    **Nova Pergunta do Utilizador:**
    {user_question}

    Responda √† nova pergunta de forma concisa e direta, usando sempre o contexto e os dados das issues fornecidos. Se o utilizador pedir exemplos, cite as chaves das issues (ex: AMS-123).
    """

    try:
        if provider == "Google Gemini":
            response = model_client.generate_content(prompt)
            return response.text
        else: # OpenAI
            response = model_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": prompt}]
            )
            return response.choices[0].message.content
    except Exception as e:
        return f"Ocorreu um erro ao processar a sua pergunta: {e}"


def get_ai_user_story_from_figma(image_url, user_context, element_name):
    """
    Usa a IA para analisar uma imagem e gerar uma Job Story completa com crit√©rios
    de aceita√ß√£o e cen√°rios de teste BDD.
    """
    user_data = find_user(st.session_state['email'])
    provider = user_data.get('ai_provider_preference', 'Google Gemini')

    model_client = _get_ai_client_and_model(provider, user_data)
    if not model_client:
        return {"error": "An√°lise indispon√≠vel."}

    prompt = f"""
    Aja como um Product Owner e um Analista de QA experientes. A sua tarefa √© analisar a imagem de um elemento de interface chamado "{element_name}" e o contexto fornecido para criar uma Hist√≥ria de Usu√°rio completa em portugu√™s, no formato JSON.

    **Contexto Adicional:**
    {user_context}

    **Regras para a Gera√ß√£o:**
    1.  **T√≠tulo (title):** Crie um t√≠tulo curto e descritivo.
    2.  **Descri√ß√£o (description):** Escreva a hist√≥ria no formato "Job Story": "Quando <situa√ß√£o>, Eu quero <motiva√ß√£o>, Ent√£o eu posso <resultado>."
    3.  **Crit√©rios de Aceita√ß√£o (acceptance_criteria):** Crie uma lista de 3 a 5 crit√©rios de aceita√ß√£o claros, separados por uma nova linha (\\n).
    4.  **Cen√°rios de Teste BDD (bdd_scenarios):** Crie 2 a 3 cen√°rios de teste detalhados no formato BDD: "Cen√°rio: <nome do cen√°rio>\\nDado <contexto>\\nE <outro contexto>\\nQuando <a√ß√£o>\\nEnt√£o <resultado esperado>", com cada cen√°rio separado por duas novas linhas (\\n\\n).

    **Estrutura de Sa√≠da (Responda APENAS com o JSON):**
    {{"title": "...", "description": "...", "acceptance_criteria": "...", "bdd_scenarios": "..."}}
    """

    try:
        if provider == "Google Gemini":
            image_response = requests.get(image_url)
            image_parts = [{"mime_type": "image/png", "data": image_response.content}]
            prompt_parts = [prompt, image_parts[0]]
            response = model_client.generate_content(prompt_parts)
            cleaned_response = response.text.strip().replace("```json", "").replace("```", "")
        else: # OpenAI
            response = model_client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt},
                            {"type": "image_url", "image_url": {"url": image_url}}
                        ]
                    }
                ],
                response_format={"type": "json_object"}
            )
            cleaned_response = response.choices[0].message.content

        return json.loads(cleaned_response)
    except Exception as e:
        return {"error": f"Ocorreu um erro ao gerar a hist√≥ria de usu√°rio: {e}"}

def get_ai_contract_analysis(pdf_bytes):
    """
    Usa a IA para analisar o texto de um contrato em PDF e extrair os campos-chave
    para uma Ordem de Servi√ßo, retornando um objeto JSON.
    """
    user_data = find_user(st.session_state['email'])
    provider = user_data.get('ai_provider_preference', 'Google Gemini')

    model_client = _get_ai_client_and_model(provider, user_data)
    if not model_client:
        return {"error": "An√°lise indispon√≠vel. Verifique a configura√ß√£o da sua chave de IA."}

    # Extrai o texto do PDF
    try:
        doc = fitz.open(stream=pdf_bytes, filetype="pdf")
        contract_text = ""
        for page in doc:
            contract_text += page.get_text()
        doc.close()
    except Exception as e:
        return {"error": f"N√£o foi poss√≠vel ler o ficheiro PDF: {e}"}

    prompt = f"""
    Aja como um Analista de Contratos s√™nior. A sua tarefa √© analisar o texto de uma Ordem de Servi√ßo (OS) ou contrato e extrair as seguintes informa√ß√µes, retornando o resultado num formato JSON.

    **Texto do Contrato para An√°lise:**
    {contract_text[:8000]} # Limita o tamanho do prompt

    **Regras para a Extra√ß√£o:**
    1.  **setor_demandante:** Identifique a √°rea ou setor que solicitou o servi√ßo.
    2.  **responsavel_demandante:** Identifique o nome do respons√°vel pela solicita√ß√£o.
    3.  **email_demandante:** Extraia o e-mail do respons√°vel.
    4.  **lider_projeto_gauge:** Identifique o nome do l√≠der de projeto do lado do fornecedor.
    5.  **data_emissao:** Encontre a data de emiss√£o do documento (formato DD/MM/AAAA).
    6.  **previsao_inicio:** Encontre a data de previs√£o de in√≠cio (formato DD/MM/AAAA).
    7.  **previsao_conclusao:** Encontre a data de previs√£o de t√©rmino (formato DD/MM/AAAA).
    8.  **justificativa_objetivo:** Fa√ßa um resumo conciso da justificativa e dos objetivos.
    9.  **escopo_tecnico:** Fa√ßa um resumo dos principais pontos do escopo t√©cnico ou dos entreg√°veis.
    10. **premissas:** Liste as premissas importantes.
    11. **orcamento:** Extraia o valor total do or√ßamento como um n√∫mero.
    12. **pagamento:** Resuma o cronograma ou as condi√ß√µes de pagamento.

    **Estrutura de Sa√≠da (Responda APENAS com o JSON. Se um campo n√£o for encontrado, retorne uma string vazia ""):**
    {{
        "setor_demandante": "", "responsavel_demandante": "", "email_demandante": "",
        "lider_projeto_gauge": "", "data_emissao": "", "previsao_inicio": "",
        "previsao_conclusao": "", "justificativa_objetivo": "", "escopo_tecnico": "",
        "premissas": "", "orcamento": 0.0, "pagamento": ""
    }}
    """

    try:
        if provider == "Google Gemini":
            response = model_client.generate_content(prompt)
            cleaned_response = response.text.strip().replace("```json", "").replace("```", "")
        else: # OpenAI
            response = model_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": prompt}],
                response_format={"type": "json_object"}
            )
            cleaned_response = response.choices[0].message.content

        return json.loads(cleaned_response)
    except Exception as e:
        return {"error": f"Ocorreu um erro ao analisar o contrato: {e}"}

def get_ai_os_from_context_and_contract(user_context, contract_text=None):
    """
    Usa a IA para analisar o contexto do utilizador e, opcionalmente, o texto de um contrato
    para preencher os campos de uma Ordem de Servi√ßo em formato JSON.
    """
    user_data = find_user(st.session_state['email'])
    provider = user_data.get('ai_provider_preference', 'Google Gemini')

    model_client = _get_ai_client_and_model(provider, user_data)
    if not model_client:
        return {"error": "An√°lise indispon√≠vel. Verifique a configura√ß√£o da sua chave de IA."}

    # --- PROMPT DIN√ÇMICO ---
    prompt_base = f"""
    Aja como um Gerente de Projetos s√™nior. A sua tarefa √© criar uma Ordem de Servi√ßo (OS) com base no contexto fornecido pelo utilizador e, se dispon√≠vel, complement√°-la com os detalhes encontrados no documento do contrato em anexo. Retorne o resultado num formato JSON.

    **Contexto da OS (Fonte Principal de Informa√ß√£o):**
    {user_context}
    """

    prompt_contrato = f"""
    **Texto do Contrato (Use para encontrar detalhes objetivos como nomes, datas, valores):**
    {contract_text[:8000]} # Limita o tamanho do prompt
    """ if contract_text else ""

    prompt_final = f"""
    {prompt_base}
    {prompt_contrato}

    **Regras para a Extra√ß√£o e Gera√ß√£o:**
    1.  Use o "Contexto da OS" como a principal fonte de verdade, especialmente para campos subjetivos como 'Justificativa & Objetivo' e 'Escopo T√©cnico'.
    2.  Use o "Texto do Contrato", se fornecido, para encontrar e extrair os valores para os outros campos.
    3.  Se um campo n√£o for encontrado em nenhuma das fontes, retorne uma string vazia "".

    **Estrutura de Sa√≠da (Responda APENAS com o JSON):**
    {{
        "setor_demandante": "", "responsavel_demandante": "", "email_demandante": "",
        "lider_projeto_gauge": "", "data_emissao": "DD/MM/AAAA", "previsao_inicio": "DD/MM/AAAA",
        "previsao_conclusao": "DD/MM/AAAA", "justificativa_objetivo": "", "escopo_tecnico": "",
        "premissas": "", "orcamento": "", "pagamento": ""
    }}
    """

    try:
        if provider == "Google Gemini":
            response = model_client.generate_content(prompt_final)
            cleaned_response = response.text.strip().replace("```json", "").replace("```", "")
        else: # OpenAI
            response = model_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": prompt_final}],
                response_format={"type": "json_object"}
            )
            cleaned_response = response.choices[0].message.content

        return json.loads(cleaned_response)
    except Exception as e:
        return {"error": f"Ocorreu um erro ao analisar o contrato: {e}"}

def get_ai_user_story_from_text(user_context):
    """
    Usa a IA para analisar o contexto do utilizador e gerar uma hist√≥ria de usu√°rio
    estruturada em JSON, no formato Job Story.
    """
    user_data = find_user(st.session_state['email'])
    provider = user_data.get('ai_provider_preference', 'Google Gemini')

    model_client = _get_ai_client_and_model(provider, user_data)
    if not model_client:
        return {"error": "An√°lise indispon√≠vel. Verifique a configura√ß√£o da sua chave de IA."}

    prompt = f"""
    Aja como um Product Owner (PO) s√™nior, especialista em criar Job Stories claras e eficazes. A sua tarefa √© analisar o contexto fornecido para criar uma Hist√≥ria de Usu√°rio completa, em portugu√™s, no formato JSON.

    **Contexto Fornecido pelo Utilizador:**
    {user_context}

    **Regras para a Gera√ß√£o:**
    1.  **T√≠tulo (title):** Crie um t√≠tulo curto e descritivo para a hist√≥ria, focado na a√ß√£o principal do utilizador.
    2.  **Descri√ß√£o (description):** Escreva a hist√≥ria estritamente no formato "Job Story": "Quando <situa√ß√£o espec√≠fica>, Eu quero <motiva√ß√£o particular>, Ent√£o eu posso <resultado desejado>."
    3.  **Crit√©rios de Aceita√ß√£o (acceptance_criteria):** Crie uma lista de 3 a 5 crit√©rios de aceita√ß√£o claros e test√°veis, no formato "Dado <contexto>, Quando <a√ß√£o>, Ent√£o <resultado>.", separados por uma nova linha (\\n).

    **Estrutura de Sa√≠da (Responda APENAS com o JSON):**
    {{"title": "...", "description": "...", "acceptance_criteria": "..."}}
    """

    try:
        if provider == "Google Gemini":
            response = model_client.generate_content(prompt)
            cleaned_response = response.text.strip().replace("```json", "").replace("```", "")
        else: # OpenAI
            response = model_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": prompt}],
                response_format={"type": "json_object"}
            )
            cleaned_response = response.choices[0].message.content

        return json.loads(cleaned_response)
    except Exception as e:
        return {"error": f"Ocorreu um erro ao gerar a hist√≥ria de usu√°rio: {e}"}

def get_ai_os_from_jira_issue(issue_data_dict, layout_fields):
    """
    Usa a IA para analisar um dicion√°rio com todos os dados de uma issue do Jira
    e preencher os campos de uma Ordem de Servi√ßo em formato JSON.
    """
    user_data = find_user(st.session_state['email'])
    provider = user_data.get('ai_provider_preference', 'Google Gemini')

    model_client = _get_ai_client_and_model(provider, user_data)
    if not model_client:
        return {"error": "An√°lise indispon√≠vel. Verifique a configura√ß√£o da sua chave de IA."}

    # Prepara a lista de campos da OS para o prompt
    field_names = [field['field_name'] for field in layout_fields]
    json_structure_example = {field_name: "" for field_name in field_names}

    # Converte o dicion√°rio de dados da issue para uma string formatada
    issue_context = "\n".join([f"- {key}: {value}" for key, value in issue_data_dict.items() if value])

    prompt = f"""
    Aja como um Gerente de Projetos s√™nior. A sua tarefa √© criar uma Ordem de Servi√ßo (OS) com base nos dados completos de uma tarefa do Jira. Retorne o resultado num formato JSON.

    **Dados Completos da Tarefa do Jira:**
    {issue_context}

    **Regras para a Extra√ß√£o e Gera√ß√£o:**
    1.  Analise TODOS os dados da tarefa para preencher os campos do JSON da forma mais precisa poss√≠vel. Use campos como 'Respons√°vel', 'Relator', 'Labels' e campos personalizados para inferir informa√ß√µes.
    2.  Para campos como "Justificativa & Objetivo" ou "Escopo T√©cnico", resuma a informa√ß√£o relevante do campo 'Descri√ß√£o' e do 'Resumo' da tarefa.
    3.  Se a informa√ß√£o para um campo espec√≠fico n√£o for encontrada em nenhum dos dados da tarefa, retorne uma string vazia "".

    **Estrutura de Sa√≠da (Responda APENAS com o JSON. Siga esta estrutura):**
    {json.dumps(json_structure_example, indent=2)}
    """

    try:
        if provider == "Google Gemini":
            response = model_client.generate_content(prompt)
            cleaned_response = response.text.strip().replace("```json", "").replace("```", "")
        else: # OpenAI
            response = model_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": prompt}],
                response_format={"type": "json_object"}
            )
            cleaned_response = response.choices[0].message.content

        return json.loads(cleaned_response)
    except Exception as e:
        return {"error": f"Ocorreu um erro ao analisar a issue do Jira: {e}"}